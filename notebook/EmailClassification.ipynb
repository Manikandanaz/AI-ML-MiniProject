{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>email</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>date wed NUMBER aug NUMBER NUMBER NUMBER NUMB...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>martin a posted tassos papadopoulos the greek ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>man threatens explosion in moscow thursday aug...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>klez the virus that won t die already the most...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>in adding cream to spaghetti carbonara which ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>i just had to jump in here as carbonara is on...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>the scotsman NUMBER august NUMBER playboy want...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>martin adamson wrote isn t it just basically a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>the scotsman thu NUMBER aug NUMBER meaningful ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>i have been trying to research via sa mirrors ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               email  label\n",
       "0   date wed NUMBER aug NUMBER NUMBER NUMBER NUMB...      0\n",
       "1  martin a posted tassos papadopoulos the greek ...      0\n",
       "2  man threatens explosion in moscow thursday aug...      0\n",
       "3  klez the virus that won t die already the most...      0\n",
       "4   in adding cream to spaghetti carbonara which ...      0\n",
       "5   i just had to jump in here as carbonara is on...      0\n",
       "6  the scotsman NUMBER august NUMBER playboy want...      0\n",
       "7  martin adamson wrote isn t it just basically a...      0\n",
       "8  the scotsman thu NUMBER aug NUMBER meaningful ...      0\n",
       "9  i have been trying to research via sa mirrors ...      0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data=pd.read_csv('spam_or_not_spam.csv')\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(2500)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['label'].where(data['label']==1).count()\n",
    "data['label'].where(data['label']==0).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3000 entries, 0 to 2999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   email   2999 non-null   object\n",
      " 1   label   3000 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 47.0+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(             label\n",
       " count  3000.000000\n",
       " mean      0.166667\n",
       " std       0.372740\n",
       " min       0.000000\n",
       " 25%       0.000000\n",
       " 50%       0.000000\n",
       " 75%       0.000000\n",
       " max       1.000000,\n",
       " None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#EDA\n",
    "data.describe(),data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "email    1\n",
       "label    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(subset=['email'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    2500\n",
       "1     499\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()\n",
    "data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "marker": {
          "color": "skyblue"
         },
         "name": "Email Type",
         "type": "bar",
         "x": [
          "Not Spam (0)",
          "Spam (1)"
         ],
         "y": [
          2500,
          499
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#C8D4E3"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Distribution of spam vs not spam"
        },
        "xaxis": {
         "title": {
          "text": "Email type"
         }
        },
        "yaxis": {
         "title": {
          "text": "Count"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.graph_objects as go\n",
    "count=data['label'].value_counts()\n",
    "fig=go.Figure(data=[go.Bar(name='Email Type',x=['Not Spam (0)','Spam (1)'],y=count,marker_color='skyblue')])\n",
    "fig.update_layout(\n",
    "    title='Distribution of spam vs not spam',\n",
    "    xaxis_title='Email type',\n",
    "    yaxis_title='Count',\n",
    "    template='plotly_white'\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hole": 0.3,
         "labels": [
          "Not Spam (0)",
          "Spam (1)"
         ],
         "marker": {
          "colors": [
           "#636EFA",
           "#EF553B"
          ]
         },
         "type": "pie",
         "values": [
          2500,
          499
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#C8D4E3"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Distribution of Spam vs Not Spam Emails"
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Creating a pie chart to visualize the distribution of spam vs not spam\n",
    "fig = go.Figure(data=[go.Pie(\n",
    "    labels=['Not Spam (0)', 'Spam (1)'],\n",
    "    values=count,\n",
    "    hole=0.3,  # For a donut chart, setting hole > 0 creates the \"donut\" effect\n",
    "    marker=dict(colors=['#636EFA', '#EF553B'])\n",
    ")])\n",
    "\n",
    "# Adding layout details\n",
    "fig.update_layout(\n",
    "    title='Distribution of Spam vs Not Spam Emails',\n",
    "    template='plotly_white'\n",
    ")\n",
    "\n",
    "# Display the plot\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "marker": {
          "color": "#FFA15A"
         },
         "name": "Not Spam",
         "nbinsx": 400,
         "opacity": 0.75,
         "type": "histogram",
         "x": [
          1522,
          643,
          1509,
          1015,
          771,
          498,
          1059,
          874,
          5677,
          657,
          368,
          821,
          998,
          1427,
          4180,
          557,
          911,
          734,
          216,
          449,
          250,
          1360,
          1461,
          743,
          820,
          2264,
          1217,
          288,
          452,
          2526,
          310,
          637,
          317,
          216,
          550,
          844,
          2585,
          1795,
          1366,
          932,
          483,
          310,
          2231,
          817,
          781,
          119,
          917,
          1050,
          472,
          4253,
          257,
          1254,
          826,
          613,
          129,
          334,
          947,
          735,
          857,
          478,
          2422,
          675,
          989,
          11556,
          113,
          560,
          1951,
          1848,
          1309,
          2279,
          310,
          675,
          872,
          3525,
          280,
          170,
          3747,
          903,
          310,
          542,
          1795,
          246,
          686,
          607,
          1077,
          260,
          4102,
          1047,
          1597,
          961,
          1386,
          427,
          894,
          1467,
          389,
          1544,
          360,
          2318,
          1032,
          613,
          941,
          346,
          993,
          1180,
          1088,
          580,
          1330,
          782,
          1731,
          558,
          957,
          1075,
          1453,
          762,
          1057,
          493,
          1530,
          976,
          1359,
          588,
          488,
          759,
          531,
          424,
          1063,
          895,
          192,
          2380,
          553,
          1474,
          892,
          824,
          760,
          541,
          851,
          804,
          460,
          1393,
          289,
          229,
          165,
          237,
          142,
          212,
          208,
          145,
          151,
          133,
          144,
          632,
          985,
          554,
          4314,
          1879,
          414,
          4202,
          1971,
          3940,
          1515,
          1670,
          1572,
          827,
          597,
          2199,
          2022,
          8020,
          406,
          545,
          871,
          176,
          606,
          1312,
          533,
          1546,
          738,
          468,
          3226,
          1936,
          3483,
          4272,
          2733,
          6611,
          3421,
          2042,
          536,
          2315,
          2251,
          1299,
          921,
          4052,
          675,
          1294,
          119,
          505,
          809,
          351,
          405,
          664,
          426,
          1175,
          425,
          612,
          296,
          1742,
          774,
          640,
          654,
          729,
          737,
          1023,
          423,
          1499,
          2134,
          1003,
          588,
          1317,
          931,
          562,
          559,
          613,
          707,
          347,
          2935,
          1368,
          7235,
          467,
          432,
          1036,
          2228,
          1293,
          805,
          2473,
          2537,
          1541,
          2118,
          325,
          313,
          800,
          824,
          2578,
          933,
          859,
          303,
          1551,
          493,
          685,
          2796,
          196,
          440,
          2541,
          4269,
          548,
          2195,
          3433,
          1781,
          614,
          502,
          850,
          279,
          509,
          5399,
          266,
          431,
          727,
          33810,
          851,
          540,
          1384,
          1462,
          830,
          10505,
          1292,
          737,
          1407,
          424,
          383,
          1084,
          974,
          604,
          2690,
          694,
          2086,
          1544,
          1013,
          632,
          849,
          602,
          925,
          729,
          406,
          1393,
          1575,
          2038,
          507,
          1397,
          356,
          313,
          887,
          1027,
          1473,
          726,
          15812,
          1998,
          1566,
          13415,
          659,
          307,
          502,
          702,
          343,
          451,
          808,
          330,
          1327,
          1978,
          367,
          3166,
          3166,
          3166,
          3059,
          5520,
          453,
          2478,
          861,
          10036,
          2420,
          1155,
          921,
          1241,
          1720,
          456,
          1280,
          1485,
          596,
          249,
          953,
          190,
          219,
          834,
          650,
          1099,
          5896,
          264,
          845,
          1493,
          756,
          815,
          341,
          1071,
          548,
          377,
          630,
          1474,
          1421,
          1408,
          379,
          796,
          3192,
          81,
          283,
          517,
          785,
          685,
          99,
          1440,
          1124,
          429,
          1400,
          1694,
          377,
          857,
          490,
          6908,
          625,
          472,
          1028,
          52,
          623,
          1021,
          584,
          613,
          5936,
          970,
          1006,
          1167,
          777,
          1315,
          1132,
          398,
          1494,
          178,
          417,
          1558,
          719,
          1165,
          1194,
          677,
          636,
          3655,
          487,
          738,
          1128,
          722,
          234,
          5201,
          738,
          1104,
          391,
          620,
          738,
          988,
          264,
          3578,
          3998,
          111,
          131,
          4080,
          3418,
          816,
          4573,
          1922,
          2228,
          3338,
          863,
          91,
          1068,
          1161,
          3456,
          1242,
          369,
          148,
          697,
          2974,
          1198,
          307,
          955,
          652,
          220,
          542,
          1027,
          553,
          839,
          3047,
          1248,
          129,
          437,
          944,
          3471,
          538,
          1849,
          7546,
          3655,
          6715,
          866,
          6833,
          1914,
          846,
          1733,
          1568,
          380,
          6833,
          1697,
          204,
          1109,
          1876,
          707,
          1163,
          309,
          1064,
          1519,
          285,
          104,
          359,
          1251,
          350,
          674,
          2261,
          2844,
          1137,
          3290,
          1356,
          3412,
          513,
          4043,
          325,
          1265,
          3678,
          1564,
          1766,
          1416,
          1222,
          341,
          670,
          566,
          739,
          1235,
          2169,
          642,
          931,
          1206,
          2702,
          422,
          124,
          2421,
          1037,
          1198,
          683,
          906,
          738,
          247,
          488,
          518,
          705,
          568,
          1839,
          2852,
          510,
          444,
          2296,
          265,
          1069,
          463,
          3193,
          776,
          148,
          1594,
          5124,
          1788,
          2034,
          718,
          977,
          982,
          838,
          1534,
          1192,
          1588,
          599,
          931,
          968,
          1053,
          5210,
          356,
          1405,
          1112,
          1106,
          677,
          630,
          7610,
          2789,
          1564,
          1872,
          2002,
          896,
          6543,
          530,
          499,
          1253,
          7839,
          7845,
          1675,
          258,
          388,
          103,
          311,
          2678,
          581,
          1052,
          1268,
          87,
          38818,
          763,
          870,
          1506,
          160,
          180,
          455,
          707,
          1543,
          1936,
          779,
          1846,
          393,
          6146,
          904,
          115,
          2564,
          1584,
          520,
          1566,
          3792,
          3244,
          2642,
          1362,
          1050,
          6260,
          107,
          3579,
          1793,
          629,
          568,
          864,
          1226,
          626,
          549,
          1706,
          1779,
          388,
          562,
          521,
          515,
          1457,
          242,
          471,
          4051,
          145,
          261,
          283,
          1004,
          1010,
          504,
          1101,
          3119,
          2377,
          1416,
          586,
          630,
          3456,
          926,
          1322,
          99,
          903,
          1216,
          346,
          1214,
          1432,
          737,
          455,
          2820,
          8777,
          612,
          1820,
          739,
          32,
          263,
          528,
          1197,
          766,
          6270,
          341,
          1516,
          277,
          536,
          1625,
          2281,
          1501,
          1431,
          1897,
          1142,
          937,
          1245,
          469,
          702,
          381,
          1015,
          464,
          405,
          2390,
          2380,
          3021,
          82638,
          750,
          1041,
          289,
          1197,
          75,
          218,
          82994,
          3421,
          2369,
          336,
          1288,
          629,
          944,
          355,
          704,
          1771,
          667,
          2455,
          294,
          417,
          571,
          641,
          365,
          291,
          372,
          1099,
          547,
          462,
          682,
          1433,
          859,
          633,
          562,
          2408,
          448,
          3626,
          1199,
          399,
          3286,
          877,
          570,
          5248,
          12706,
          1979,
          153,
          4630,
          5439,
          1470,
          10447,
          1627,
          1217,
          400,
          593,
          962,
          2449,
          2290,
          676,
          2402,
          510,
          183,
          210,
          393,
          5926,
          4043,
          6736,
          804,
          749,
          4620,
          188,
          823,
          1147,
          980,
          304,
          6769,
          5280,
          8634,
          6148,
          624,
          641,
          684,
          1096,
          303,
          346,
          349,
          920,
          597,
          481,
          1361,
          193,
          156,
          2018,
          243,
          441,
          138,
          34176,
          791,
          1473,
          400,
          1316,
          2959,
          2550,
          423,
          452,
          360,
          615,
          2444,
          1098,
          483,
          1369,
          5763,
          4959,
          2287,
          848,
          361,
          1301,
          329,
          207,
          207,
          310,
          187,
          860,
          469,
          8321,
          1194,
          430,
          1364,
          2392,
          2822,
          3430,
          2150,
          1358,
          731,
          483,
          885,
          2197,
          570,
          5,
          10361,
          1735,
          1359,
          4182,
          443,
          1100,
          67,
          1898,
          473,
          998,
          1447,
          1269,
          578,
          1368,
          1464,
          500,
          1363,
          608,
          545,
          1235,
          3461,
          2094,
          589,
          6820,
          589,
          1443,
          52,
          7095,
          1589,
          288,
          757,
          292,
          799,
          1016,
          757,
          1780,
          731,
          2130,
          716,
          1744,
          328,
          738,
          1128,
          2140,
          384,
          556,
          402,
          3075,
          1543,
          1276,
          3644,
          417,
          489,
          1609,
          355,
          1892,
          481,
          2167,
          3944,
          441,
          1788,
          483,
          1170,
          872,
          483,
          234,
          313,
          253,
          1643,
          464,
          2091,
          3081,
          545,
          105,
          236,
          784,
          236,
          2161,
          1496,
          388,
          1791,
          947,
          670,
          716,
          1130,
          15132,
          501,
          927,
          2359,
          1381,
          184,
          372,
          662,
          773,
          947,
          494,
          1888,
          1197,
          396,
          754,
          1291,
          297,
          609,
          1363,
          1937,
          2621,
          1603,
          290,
          2661,
          492,
          529,
          180,
          598,
          808,
          829,
          919,
          456,
          1325,
          2128,
          772,
          365,
          972,
          825,
          19152,
          1463,
          402,
          19562,
          591,
          19820,
          1434,
          5253,
          1425,
          1251,
          6201,
          35669,
          11623,
          1004,
          1210,
          641,
          1151,
          2659,
          760,
          1474,
          890,
          1057,
          689,
          1081,
          1751,
          2428,
          857,
          6176,
          400,
          1100,
          674,
          1458,
          2341,
          1373,
          2344,
          1025,
          2232,
          1530,
          1881,
          1003,
          760,
          1346,
          3452,
          750,
          512,
          498,
          698,
          396,
          1302,
          594,
          1134,
          737,
          458,
          664,
          372,
          755,
          1244,
          440,
          871,
          1160,
          495,
          1989,
          858,
          437,
          688,
          841,
          717,
          847,
          1293,
          990,
          1189,
          1611,
          738,
          1514,
          1878,
          607,
          939,
          1045,
          1344,
          919,
          636,
          1989,
          757,
          1410,
          697,
          572,
          1052,
          2080,
          1016,
          1532,
          821,
          1064,
          1284,
          1377,
          1679,
          329,
          896,
          330,
          437,
          1166,
          2380,
          516,
          265,
          709,
          940,
          1406,
          889,
          828,
          1272,
          1251,
          1899,
          977,
          2614,
          879,
          4054,
          3240,
          1341,
          1096,
          341,
          3503,
          307,
          438,
          753,
          728,
          742,
          1175,
          392,
          1123,
          525,
          434,
          510,
          1249,
          1114,
          820,
          173,
          620,
          525,
          772,
          729,
          654,
          1604,
          2064,
          1216,
          1393,
          1119,
          2730,
          839,
          1045,
          614,
          559,
          1123,
          949,
          296,
          2175,
          1126,
          1060,
          571,
          582,
          543,
          910,
          647,
          605,
          887,
          1497,
          1957,
          655,
          552,
          781,
          1373,
          712,
          399,
          878,
          531,
          969,
          701,
          415,
          400,
          1258,
          427,
          1443,
          363,
          631,
          1239,
          583,
          276,
          353,
          839,
          738,
          1444,
          842,
          420,
          1532,
          2583,
          977,
          1584,
          2199,
          1685,
          3349,
          2015,
          1375,
          2814,
          1689,
          1586,
          1064,
          479,
          969,
          883,
          552,
          515,
          1182,
          2880,
          1521,
          304,
          1003,
          822,
          1162,
          516,
          832,
          595,
          949,
          494,
          1144,
          488,
          560,
          1383,
          760,
          816,
          1107,
          654,
          2157,
          4319,
          1073,
          1217,
          1516,
          1765,
          1734,
          743,
          535,
          855,
          1109,
          379,
          727,
          326,
          1220,
          570,
          2024,
          919,
          1844,
          547,
          340,
          371,
          654,
          1447,
          1079,
          1183,
          865,
          985,
          445,
          815,
          995,
          1954,
          885,
          1033,
          1364,
          306,
          853,
          515,
          1842,
          426,
          1435,
          861,
          465,
          885,
          1297,
          527,
          1272,
          356,
          1137,
          455,
          1291,
          887,
          931,
          870,
          1386,
          2452,
          1224,
          1348,
          1625,
          754,
          1305,
          829,
          1243,
          1735,
          2205,
          739,
          620,
          1501,
          756,
          362,
          839,
          1615,
          610,
          679,
          718,
          623,
          659,
          470,
          745,
          940,
          565,
          700,
          140,
          735,
          897,
          783,
          1064,
          1445,
          3847,
          1378,
          1471,
          700,
          326,
          856,
          1346,
          770,
          1822,
          1195,
          223,
          520,
          825,
          699,
          232,
          879,
          255,
          376,
          781,
          223,
          614,
          801,
          697,
          1323,
          5609,
          975,
          1632,
          1369,
          1366,
          643,
          705,
          327,
          192,
          660,
          541,
          430,
          907,
          613,
          2289,
          1632,
          2162,
          1720,
          1932,
          861,
          606,
          1397,
          1048,
          467,
          811,
          890,
          999,
          823,
          886,
          334,
          1292,
          3830,
          524,
          739,
          865,
          667,
          5901,
          494,
          487,
          481,
          1298,
          1075,
          1165,
          1102,
          981,
          749,
          1034,
          863,
          1246,
          1516,
          1336,
          456,
          914,
          609,
          992,
          1112,
          704,
          289,
          1158,
          545,
          736,
          427,
          493,
          415,
          802,
          1821,
          2470,
          1081,
          312,
          361,
          801,
          838,
          612,
          912,
          450,
          1002,
          1223,
          863,
          565,
          2888,
          1396,
          934,
          624,
          479,
          1422,
          660,
          719,
          1540,
          1854,
          758,
          1455,
          1001,
          1518,
          894,
          3076,
          446,
          1002,
          1199,
          951,
          11075,
          513,
          1202,
          1054,
          2938,
          440,
          1615,
          3836,
          643,
          973,
          836,
          1408,
          2398,
          1286,
          869,
          677,
          1057,
          657,
          956,
          1036,
          546,
          861,
          423,
          141,
          2133,
          1259,
          378,
          687,
          1164,
          590,
          863,
          1022,
          830,
          623,
          1039,
          646,
          1424,
          754,
          731,
          1102,
          1986,
          1879,
          1079,
          1745,
          381,
          215,
          1882,
          187,
          1195,
          1660,
          1851,
          1250,
          1451,
          606,
          736,
          646,
          1117,
          420,
          456,
          536,
          528,
          945,
          1068,
          998,
          1611,
          242,
          1207,
          403,
          694,
          1227,
          555,
          810,
          1401,
          360,
          266,
          716,
          868,
          574,
          766,
          1622,
          843,
          841,
          558,
          499,
          311,
          1522,
          1906,
          388,
          676,
          1679,
          1144,
          362,
          1101,
          1598,
          727,
          1376,
          1615,
          1389,
          1786,
          1190,
          527,
          1126,
          2078,
          1494,
          632,
          982,
          328,
          621,
          618,
          796,
          839,
          769,
          315,
          971,
          1578,
          386,
          837,
          1074,
          790,
          813,
          569,
          590,
          369,
          909,
          975,
          575,
          566,
          529,
          450,
          1673,
          901,
          1685,
          2448,
          435,
          539,
          981,
          106,
          981,
          744,
          206,
          1485,
          1148,
          1044,
          3164,
          934,
          1561,
          2970,
          545,
          533,
          659,
          1120,
          2937,
          501,
          544,
          468,
          513,
          1011,
          529,
          8401,
          583,
          2359,
          992,
          560,
          456,
          813,
          449,
          1120,
          762,
          888,
          654,
          914,
          106,
          386,
          557,
          1730,
          2040,
          1108,
          756,
          516,
          807,
          1736,
          2443,
          405,
          12626,
          1281,
          463,
          895,
          579,
          3183,
          531,
          1443,
          829,
          1092,
          628,
          659,
          1855,
          455,
          1369,
          1495,
          763,
          893,
          1209,
          1217,
          442,
          859,
          2066,
          810,
          870,
          1126,
          1206,
          515,
          341,
          953,
          6130,
          648,
          599,
          328,
          430,
          865,
          1026,
          1668,
          408,
          760,
          838,
          1281,
          1692,
          603,
          664,
          371,
          861,
          876,
          450,
          782,
          549,
          1093,
          1406,
          924,
          588,
          1042,
          2567,
          1231,
          725,
          674,
          792,
          1508,
          1131,
          951,
          3015,
          1053,
          5541,
          729,
          1210,
          792,
          3796,
          672,
          2693,
          4229,
          1300,
          1211,
          2399,
          3107,
          1943,
          740,
          2516,
          1334,
          369,
          515,
          573,
          456,
          923,
          1507,
          273,
          1052,
          2378,
          1041,
          1920,
          1163,
          1177,
          1111,
          1147,
          529,
          360,
          756,
          1259,
          2528,
          599,
          723,
          3278,
          1014,
          488,
          2453,
          2094,
          1894,
          451,
          658,
          1088,
          1722,
          537,
          665,
          562,
          1063,
          1172,
          1708,
          634,
          1656,
          240,
          649,
          401,
          3887,
          1712,
          836,
          556,
          5392,
          883,
          421,
          830,
          159,
          690,
          366,
          596,
          237,
          133,
          248,
          1175,
          926,
          614,
          501,
          335,
          316,
          125,
          353,
          714,
          753,
          2731,
          4056,
          685,
          1349,
          890,
          181,
          362,
          528,
          1672,
          13418,
          2529,
          8275,
          3124,
          810,
          735,
          1227,
          2853,
          840,
          426,
          1254,
          1103,
          279,
          606,
          1382,
          231,
          2985,
          501,
          961,
          2222,
          336,
          291,
          217,
          552,
          381,
          1170,
          174,
          1438,
          931,
          364,
          4384,
          2619,
          2726,
          638,
          954,
          465,
          2251,
          6163,
          2065,
          464,
          464,
          4840,
          1329,
          283,
          782,
          386,
          655,
          1791,
          554,
          1380,
          690,
          1400,
          1052,
          588,
          860,
          441,
          878,
          441,
          908,
          425,
          960,
          1334,
          588,
          636,
          1820,
          426,
          835,
          758,
          481,
          785,
          444,
          936,
          448,
          1180,
          455,
          784,
          651,
          2029,
          1196,
          443,
          865,
          1430,
          1639,
          457,
          1108,
          438,
          786,
          437,
          838,
          584,
          1725,
          461,
          757,
          481,
          806,
          784,
          428,
          2502,
          557,
          1137,
          906,
          480,
          412,
          930,
          960,
          809,
          383,
          399,
          533,
          1461,
          707,
          837,
          711,
          896,
          149,
          852,
          119,
          122,
          638,
          128,
          1030,
          447,
          325,
          739,
          1161,
          137,
          524,
          195,
          870,
          214,
          214,
          1374,
          116,
          250,
          113,
          119,
          312,
          122,
          317,
          366,
          280,
          306,
          2061,
          1891,
          195,
          443,
          794,
          109,
          2299,
          274,
          560,
          130,
          853,
          1266,
          1693,
          118,
          127,
          178,
          265,
          315,
          120,
          207,
          191,
          115,
          296,
          116,
          143,
          162,
          648,
          339,
          407,
          171,
          833,
          362,
          1001,
          313,
          1205,
          652,
          744,
          525,
          1228,
          456,
          696,
          658,
          506,
          256,
          1059,
          505,
          125,
          235,
          287,
          144,
          219,
          829,
          206,
          281,
          1016,
          644,
          449,
          682,
          102,
          122,
          1309,
          351,
          388,
          139,
          243,
          169,
          265,
          908,
          145,
          601,
          319,
          387,
          1321,
          2935,
          2637,
          242,
          359,
          2689,
          604,
          4204,
          835,
          1603,
          1291,
          954,
          1932,
          83,
          81,
          89,
          2104,
          83,
          2082,
          83,
          290,
          84,
          215,
          533,
          231,
          90,
          678,
          30,
          1097,
          30,
          30,
          30,
          30,
          30,
          268,
          30,
          145,
          293,
          164,
          152,
          154,
          139,
          141,
          157,
          156,
          146,
          159,
          138,
          145,
          143,
          151,
          143,
          154,
          154,
          145,
          155,
          143,
          142,
          158,
          177,
          137,
          142,
          159,
          3551,
          197,
          167,
          282,
          277,
          87,
          89,
          278,
          292,
          86,
          84,
          72,
          83,
          485,
          86,
          506,
          87,
          256,
          648,
          163,
          30,
          211,
          94,
          83,
          1360,
          965,
          85,
          87,
          86,
          92,
          92,
          474,
          81,
          81,
          86,
          81,
          84,
          240,
          353,
          78,
          280,
          93,
          143,
          452,
          548,
          515,
          307,
          147,
          479,
          189,
          159,
          145,
          131,
          320,
          180,
          505,
          337,
          160,
          265,
          548,
          130,
          515,
          353,
          431,
          193,
          452,
          182,
          94,
          701,
          1542,
          1267,
          251,
          105,
          138,
          174,
          142,
          149,
          412,
          184,
          193,
          353,
          179,
          452,
          479,
          179,
          264,
          287,
          431,
          548,
          265,
          175,
          505,
          337,
          515,
          252,
          141,
          209,
          1505,
          670,
          1378,
          230,
          83,
          439,
          88,
          170,
          73,
          89,
          214,
          154,
          117,
          123,
          92,
          239,
          89,
          172,
          83,
          30,
          81,
          193,
          92,
          30,
          277,
          93,
          83,
          85,
          88,
          125,
          739,
          84,
          81,
          84,
          227,
          80,
          78,
          92,
          204,
          83,
          479,
          501,
          85,
          202,
          93,
          78,
          452,
          137,
          300,
          153,
          266,
          80,
          431,
          255,
          457,
          85,
          80,
          83,
          94,
          79,
          168,
          149,
          150,
          85,
          281,
          240,
          353,
          83,
          81,
          81,
          88,
          73,
          83,
          505,
          80,
          187,
          337,
          87,
          515,
          83,
          548,
          74,
          93,
          832,
          284,
          1489,
          250,
          248,
          258,
          233,
          157,
          158,
          221,
          136,
          119,
          243,
          268,
          487,
          128,
          1238,
          139,
          148,
          1369,
          366,
          266,
          819,
          1275,
          174,
          334,
          401,
          435,
          3728,
          327,
          1261,
          594,
          266,
          162,
          1830,
          194,
          175,
          269,
          262,
          891,
          213,
          269,
          241,
          1483,
          477,
          197,
          159,
          135,
          146,
          159,
          540,
          161,
          302,
          169,
          282,
          307,
          151,
          123,
          285,
          259,
          1405,
          200,
          749,
          295,
          413,
          139,
          1721,
          244,
          266,
          275,
          248,
          200,
          394,
          5475,
          1539,
          1355,
          1731,
          402,
          164,
          566,
          578,
          140,
          956,
          214,
          263,
          151,
          268,
          172,
          925,
          170,
          233,
          153,
          189,
          164,
          166,
          230,
          178,
          168,
          1148,
          146,
          135,
          177,
          149,
          182,
          169,
          117,
          142,
          145,
          157,
          188,
          946,
          163,
          175,
          410,
          135,
          643,
          769,
          442,
          287,
          150,
          131,
          177,
          167,
          225,
          252,
          1798,
          233,
          156,
          341,
          215,
          372,
          416,
          497,
          245,
          506,
          223,
          210,
          411,
          475,
          1151,
          603,
          366,
          222,
          1101,
          506,
          289,
          166,
          423,
          157,
          213,
          650,
          468,
          290,
          485,
          1450,
          219,
          504,
          268,
          533,
          179,
          334,
          822,
          243,
          409,
          594,
          648,
          392,
          614,
          2084,
          629,
          474,
          184,
          97,
          183,
          141,
          183,
          191,
          145,
          138,
          1714,
          186,
          661,
          320,
          6398,
          1421,
          329,
          699,
          267,
          346,
          299,
          168,
          257,
          103,
          112,
          377,
          235,
          249,
          301,
          222,
          156,
          539,
          180,
          866,
          240,
          238,
          608,
          871,
          3872,
          7370,
          225,
          962,
          651,
          168,
          142,
          183,
          445,
          252,
          228,
          149,
          115,
          381,
          141,
          236,
          157,
          113,
          136,
          152,
          156,
          125,
          6446,
          299,
          823,
          234,
          279,
          1131,
          219,
          2333,
          619,
          606,
          170,
          223,
          189,
          242,
          149,
          133,
          144,
          281,
          157,
          274,
          365,
          131,
          162,
          161,
          128,
          172,
          210,
          151,
          144,
          152,
          139,
          121,
          136,
          148,
          6253,
          406,
          205,
          260,
          464,
          3341,
          8639,
          748,
          1327,
          298,
          3320,
          902,
          925,
          609,
          3023,
          493,
          892,
          601,
          1247,
          222,
          1634,
          994,
          1088,
          1222,
          805,
          544,
          1482,
          604,
          361,
          561,
          345,
          915,
          377,
          317,
          352,
          353,
          3312,
          1215,
          1131,
          981,
          766,
          363,
          247,
          546,
          1488,
          742,
          942,
          2271,
          503,
          469,
          4488,
          234,
          1383,
          416,
          375,
          507,
          801,
          1253,
          404,
          811,
          1288,
          974,
          275,
          979,
          1618,
          326,
          840,
          1313
         ]
        },
        {
         "marker": {
          "color": "#1f77b4"
         },
         "name": "Spam",
         "nbinsx": 400,
         "opacity": 0.75,
         "type": "histogram",
         "x": [
          989,
          487,
          387,
          2465,
          406,
          2394,
          638,
          3245,
          2809,
          1500,
          784,
          216,
          387,
          953,
          602,
          2403,
          661,
          2470,
          332,
          487,
          2513,
          2701,
          1375,
          541,
          186,
          2470,
          387,
          392,
          686,
          1235,
          3349,
          487,
          1663,
          871,
          1966,
          14544,
          624,
          632,
          16143,
          926,
          826,
          206,
          688,
          873,
          387,
          997,
          364,
          136,
          514,
          691,
          665,
          727,
          892,
          845,
          454,
          3235,
          332,
          687,
          256,
          224,
          249,
          454,
          582,
          224,
          1036,
          394,
          1291,
          492,
          2540,
          718,
          1377,
          61,
          554,
          485,
          454,
          454,
          2522,
          259,
          454,
          1039,
          801,
          1372,
          602,
          2999,
          15704,
          557,
          1016,
          820,
          551,
          979,
          186,
          520,
          957,
          873,
          886,
          1085,
          701,
          424,
          704,
          2567,
          1132,
          399,
          845,
          1500,
          1941,
          2688,
          120,
          332,
          1094,
          280,
          568,
          3876,
          584,
          586,
          566,
          355,
          812,
          1051,
          1341,
          269,
          1291,
          405,
          873,
          269,
          392,
          286,
          701,
          566,
          500,
          816,
          508,
          876,
          679,
          870,
          917,
          366,
          1278,
          1373,
          41,
          573,
          873,
          2573,
          922,
          672,
          204,
          1209,
          389,
          1362,
          1103,
          1090,
          42,
          561,
          677,
          879,
          3354,
          1365,
          2499,
          42,
          6094,
          1018,
          380,
          2099,
          936,
          566,
          991,
          872,
          2973,
          327,
          2448,
          364,
          332,
          1365,
          908,
          730,
          769,
          438,
          1346,
          845,
          989,
          839,
          677,
          17938,
          1346,
          1476,
          263,
          1195,
          847,
          1132,
          2973,
          291,
          902,
          1246,
          2142,
          240,
          1149,
          1392,
          18941,
          224,
          1346,
          2259,
          1304,
          528,
          901,
          528,
          522,
          828,
          2717,
          2257,
          1308,
          1002,
          3786,
          186,
          1240,
          705,
          1209,
          2281,
          2567,
          2940,
          1766,
          2852,
          186,
          1158,
          764,
          2675,
          674,
          951,
          2610,
          2774,
          1616,
          487,
          1230,
          1306,
          2973,
          2758,
          1780,
          2418,
          6744,
          1039,
          2657,
          808,
          1003,
          808,
          596,
          194,
          69860,
          605,
          4349,
          1177,
          585,
          9185,
          1392,
          393,
          2662,
          9196,
          9159,
          813,
          10290,
          10293,
          4691,
          515,
          1266,
          1266,
          160,
          894,
          1156,
          424,
          2983,
          808,
          812,
          3030,
          1687,
          375,
          3606,
          1132,
          1032,
          150,
          1795,
          2037,
          1913,
          1127,
          671,
          16266,
          2621,
          850,
          1437,
          3018,
          1729,
          41,
          574,
          4800,
          1195,
          1150,
          284,
          966,
          868,
          352,
          352,
          1746,
          487,
          476,
          998,
          1766,
          910,
          268,
          982,
          644,
          1,
          1003,
          939,
          1559,
          284,
          4173,
          1992,
          61,
          2189,
          7829,
          3668,
          3644,
          17374,
          159,
          773,
          300,
          160,
          164,
          375,
          375,
          375,
          3644,
          1,
          391,
          2973,
          3262,
          3262,
          3262,
          3262,
          583,
          1662,
          284,
          1046,
          1391,
          1737,
          1174,
          891,
          1520,
          434,
          4123,
          1699,
          146,
          675,
          306,
          339,
          2560,
          74,
          2519,
          880,
          2051,
          1132,
          1010,
          2923,
          190,
          2907,
          2683,
          15448,
          394,
          1520,
          1059,
          2051,
          339,
          922,
          899,
          852,
          8255,
          992,
          563,
          658,
          466,
          2151,
          1309,
          429,
          1792,
          3174,
          2051,
          1870,
          763,
          1236,
          864,
          722,
          1203,
          2223,
          2223,
          655,
          505,
          610,
          404,
          2458,
          907,
          272,
          469,
          1941,
          1249,
          1123,
          1446,
          2036,
          547,
          16561,
          268,
          164,
          1236,
          3206,
          929,
          1614,
          1339,
          689,
          830,
          964,
          1026,
          2458,
          199,
          1315,
          1013,
          401,
          15511,
          15411,
          1026,
          391,
          1505,
          8229,
          651,
          1166,
          2514,
          852,
          2303,
          364,
          879,
          1726,
          498,
          1562,
          585,
          718,
          406,
          430,
          495,
          581,
          2868,
          3001,
          580,
          936,
          2614,
          503,
          7156,
          1034,
          1198,
          113,
          675,
          2973,
          1228,
          321,
          961,
          687,
          3057,
          1416,
          2312,
          1614,
          852,
          3043,
          2466,
          480,
          332,
          1784,
          514,
          151,
          2659,
          1304,
          940,
          16295,
          915,
          1633,
          209,
          2738,
          200408,
          1015,
          1622,
          2780,
          2773,
          3272,
          974,
          1037,
          22067,
          1091,
          956,
          956,
          1470,
          2320,
          3261,
          561,
          468,
          864,
          4129,
          1981
         ]
        }
       ],
       "layout": {
        "bargap": 0.1,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#C8D4E3"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Distribution of Email Lengths"
        },
        "xaxis": {
         "range": [
          0,
          200408
         ],
         "title": {
          "text": "Email Length (characters)"
         }
        },
        "yaxis": {
         "title": {
          "text": "Frequency"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Creating an interactive histogram for email length distribution with better binning using Plotly Graph Objects\n",
    "fig = go.Figure()\n",
    "max_length = data['email_length'].max()\n",
    "\n",
    "# Adding histogram for email length\n",
    "fig.add_trace(go.Histogram(\n",
    "    x=data[data['label']==0]['email_length'],\n",
    "    nbinsx=400,\n",
    "    name='Not Spam',\n",
    "    marker_color='#FFA15A',\n",
    "    opacity=0.75\n",
    "))\n",
    "\n",
    "\n",
    "# Adding histogram for email length\n",
    "fig.add_trace(go.Histogram(\n",
    "    x=data[data['label']==1]['email_length'],\n",
    "    nbinsx=400,\n",
    "    name='Spam',\n",
    "    marker_color='#1f77b4',\n",
    "    opacity=0.75\n",
    "))\n",
    "\n",
    "# Updating layout details for better visualization\n",
    "fig.update_layout(\n",
    "    title='Distribution of Email Lengths',\n",
    "    xaxis_title='Email Length (characters)',\n",
    "    yaxis_title='Frequency',\n",
    "    template='plotly_white',\n",
    "    bargap=0.1,\n",
    "    xaxis=dict(range=[0, max_length])\n",
    ")\n",
    "\n",
    "# Display the plot\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "Email Type (0 = Not Spam, 1 = Spam)=%{marker.color}<br>Email Length (characters)=%{y}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1
          ],
          "coloraxis": "coloraxis",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "",
         "showlegend": false,
         "type": "scattergl",
         "x": [
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1
         ],
         "xaxis": "x",
         "y": [
          1522,
          643,
          1509,
          1015,
          771,
          498,
          1059,
          874,
          5677,
          657,
          368,
          821,
          998,
          1427,
          4180,
          557,
          911,
          734,
          216,
          449,
          250,
          1360,
          1461,
          743,
          820,
          2264,
          1217,
          288,
          452,
          2526,
          310,
          637,
          317,
          216,
          550,
          844,
          2585,
          1795,
          1366,
          932,
          483,
          310,
          2231,
          817,
          781,
          119,
          917,
          1050,
          472,
          4253,
          257,
          1254,
          826,
          613,
          129,
          334,
          947,
          735,
          857,
          478,
          2422,
          675,
          989,
          11556,
          113,
          560,
          1951,
          1848,
          1309,
          2279,
          310,
          675,
          872,
          3525,
          280,
          170,
          3747,
          903,
          310,
          542,
          1795,
          246,
          686,
          607,
          1077,
          260,
          4102,
          1047,
          1597,
          961,
          1386,
          427,
          894,
          1467,
          389,
          1544,
          360,
          2318,
          1032,
          613,
          941,
          346,
          993,
          1180,
          1088,
          580,
          1330,
          782,
          1731,
          558,
          957,
          1075,
          1453,
          762,
          1057,
          493,
          1530,
          976,
          1359,
          588,
          488,
          759,
          531,
          424,
          1063,
          895,
          192,
          2380,
          553,
          1474,
          892,
          824,
          760,
          541,
          851,
          804,
          460,
          1393,
          289,
          229,
          165,
          237,
          142,
          212,
          208,
          145,
          151,
          133,
          144,
          632,
          985,
          554,
          4314,
          1879,
          414,
          4202,
          1971,
          3940,
          1515,
          1670,
          1572,
          827,
          597,
          2199,
          2022,
          8020,
          406,
          545,
          871,
          176,
          606,
          1312,
          533,
          1546,
          738,
          468,
          3226,
          1936,
          3483,
          4272,
          2733,
          6611,
          3421,
          2042,
          536,
          2315,
          2251,
          1299,
          921,
          4052,
          675,
          1294,
          119,
          505,
          809,
          351,
          405,
          664,
          426,
          1175,
          425,
          612,
          296,
          1742,
          774,
          640,
          654,
          729,
          737,
          1023,
          423,
          1499,
          2134,
          1003,
          588,
          1317,
          931,
          562,
          559,
          613,
          707,
          347,
          2935,
          1368,
          7235,
          467,
          432,
          1036,
          2228,
          1293,
          805,
          2473,
          2537,
          1541,
          2118,
          325,
          313,
          800,
          824,
          2578,
          933,
          859,
          303,
          1551,
          493,
          685,
          2796,
          196,
          440,
          2541,
          4269,
          548,
          2195,
          3433,
          1781,
          614,
          502,
          850,
          279,
          509,
          5399,
          266,
          431,
          727,
          33810,
          851,
          540,
          1384,
          1462,
          830,
          10505,
          1292,
          737,
          1407,
          424,
          383,
          1084,
          974,
          604,
          2690,
          694,
          2086,
          1544,
          1013,
          632,
          849,
          602,
          925,
          729,
          406,
          1393,
          1575,
          2038,
          507,
          1397,
          356,
          313,
          887,
          1027,
          1473,
          726,
          15812,
          1998,
          1566,
          13415,
          659,
          307,
          502,
          702,
          343,
          451,
          808,
          330,
          1327,
          1978,
          367,
          3166,
          3166,
          3166,
          3059,
          5520,
          453,
          2478,
          861,
          10036,
          2420,
          1155,
          921,
          1241,
          1720,
          456,
          1280,
          1485,
          596,
          249,
          953,
          190,
          219,
          834,
          650,
          1099,
          5896,
          264,
          845,
          1493,
          756,
          815,
          341,
          1071,
          548,
          377,
          630,
          1474,
          1421,
          1408,
          379,
          796,
          3192,
          81,
          283,
          517,
          785,
          685,
          99,
          1440,
          1124,
          429,
          1400,
          1694,
          377,
          857,
          490,
          6908,
          625,
          472,
          1028,
          52,
          623,
          1021,
          584,
          613,
          5936,
          970,
          1006,
          1167,
          777,
          1315,
          1132,
          398,
          1494,
          178,
          417,
          1558,
          719,
          1165,
          1194,
          677,
          636,
          3655,
          487,
          738,
          1128,
          722,
          234,
          5201,
          738,
          1104,
          391,
          620,
          738,
          988,
          264,
          3578,
          3998,
          111,
          131,
          4080,
          3418,
          816,
          4573,
          1922,
          2228,
          3338,
          863,
          91,
          1068,
          1161,
          3456,
          1242,
          369,
          148,
          697,
          2974,
          1198,
          307,
          955,
          652,
          220,
          542,
          1027,
          553,
          839,
          3047,
          1248,
          129,
          437,
          944,
          3471,
          538,
          1849,
          7546,
          3655,
          6715,
          866,
          6833,
          1914,
          846,
          1733,
          1568,
          380,
          6833,
          1697,
          204,
          1109,
          1876,
          707,
          1163,
          309,
          1064,
          1519,
          285,
          104,
          359,
          1251,
          350,
          674,
          2261,
          2844,
          1137,
          3290,
          1356,
          3412,
          513,
          4043,
          325,
          1265,
          3678,
          1564,
          1766,
          1416,
          1222,
          341,
          670,
          566,
          739,
          1235,
          2169,
          642,
          931,
          1206,
          2702,
          422,
          124,
          2421,
          1037,
          1198,
          683,
          906,
          738,
          247,
          488,
          518,
          705,
          568,
          1839,
          2852,
          510,
          444,
          2296,
          265,
          1069,
          463,
          3193,
          776,
          148,
          1594,
          5124,
          1788,
          2034,
          718,
          977,
          982,
          838,
          1534,
          1192,
          1588,
          599,
          931,
          968,
          1053,
          5210,
          356,
          1405,
          1112,
          1106,
          677,
          630,
          7610,
          2789,
          1564,
          1872,
          2002,
          896,
          6543,
          530,
          499,
          1253,
          7839,
          7845,
          1675,
          258,
          388,
          103,
          311,
          2678,
          581,
          1052,
          1268,
          87,
          38818,
          763,
          870,
          1506,
          160,
          180,
          455,
          707,
          1543,
          1936,
          779,
          1846,
          393,
          6146,
          904,
          115,
          2564,
          1584,
          520,
          1566,
          3792,
          3244,
          2642,
          1362,
          1050,
          6260,
          107,
          3579,
          1793,
          629,
          568,
          864,
          1226,
          626,
          549,
          1706,
          1779,
          388,
          562,
          521,
          515,
          1457,
          242,
          471,
          4051,
          145,
          261,
          283,
          1004,
          1010,
          504,
          1101,
          3119,
          2377,
          1416,
          586,
          630,
          3456,
          926,
          1322,
          99,
          903,
          1216,
          346,
          1214,
          1432,
          737,
          455,
          2820,
          8777,
          612,
          1820,
          739,
          32,
          263,
          528,
          1197,
          766,
          6270,
          341,
          1516,
          277,
          536,
          1625,
          2281,
          1501,
          1431,
          1897,
          1142,
          937,
          1245,
          469,
          702,
          381,
          1015,
          464,
          405,
          2390,
          2380,
          3021,
          82638,
          750,
          1041,
          289,
          1197,
          75,
          218,
          82994,
          3421,
          2369,
          336,
          1288,
          629,
          944,
          355,
          704,
          1771,
          667,
          2455,
          294,
          417,
          571,
          641,
          365,
          291,
          372,
          1099,
          547,
          462,
          682,
          1433,
          859,
          633,
          562,
          2408,
          448,
          3626,
          1199,
          399,
          3286,
          877,
          570,
          5248,
          12706,
          1979,
          153,
          4630,
          5439,
          1470,
          10447,
          1627,
          1217,
          400,
          593,
          962,
          2449,
          2290,
          676,
          2402,
          510,
          183,
          210,
          393,
          5926,
          4043,
          6736,
          804,
          749,
          4620,
          188,
          823,
          1147,
          980,
          304,
          6769,
          5280,
          8634,
          6148,
          624,
          641,
          684,
          1096,
          303,
          346,
          349,
          920,
          597,
          481,
          1361,
          193,
          156,
          2018,
          243,
          441,
          138,
          34176,
          791,
          1473,
          400,
          1316,
          2959,
          2550,
          423,
          452,
          360,
          615,
          2444,
          1098,
          483,
          1369,
          5763,
          4959,
          2287,
          848,
          361,
          1301,
          329,
          207,
          207,
          310,
          187,
          860,
          469,
          8321,
          1194,
          430,
          1364,
          2392,
          2822,
          3430,
          2150,
          1358,
          731,
          483,
          885,
          2197,
          570,
          5,
          10361,
          1735,
          1359,
          4182,
          443,
          1100,
          67,
          1898,
          473,
          998,
          1447,
          1269,
          578,
          1368,
          1464,
          500,
          1363,
          608,
          545,
          1235,
          3461,
          2094,
          589,
          6820,
          589,
          1443,
          52,
          7095,
          1589,
          288,
          757,
          292,
          799,
          1016,
          757,
          1780,
          731,
          2130,
          716,
          1744,
          328,
          738,
          1128,
          2140,
          384,
          556,
          402,
          3075,
          1543,
          1276,
          3644,
          417,
          489,
          1609,
          355,
          1892,
          481,
          2167,
          3944,
          441,
          1788,
          483,
          1170,
          872,
          483,
          234,
          313,
          253,
          1643,
          464,
          2091,
          3081,
          545,
          105,
          236,
          784,
          236,
          2161,
          1496,
          388,
          1791,
          947,
          670,
          716,
          1130,
          15132,
          501,
          927,
          2359,
          1381,
          184,
          372,
          662,
          773,
          947,
          494,
          1888,
          1197,
          396,
          754,
          1291,
          297,
          609,
          1363,
          1937,
          2621,
          1603,
          290,
          2661,
          492,
          529,
          180,
          598,
          808,
          829,
          919,
          456,
          1325,
          2128,
          772,
          365,
          972,
          825,
          19152,
          1463,
          402,
          19562,
          591,
          19820,
          1434,
          5253,
          1425,
          1251,
          6201,
          35669,
          11623,
          1004,
          1210,
          641,
          1151,
          2659,
          760,
          1474,
          890,
          1057,
          689,
          1081,
          1751,
          2428,
          857,
          6176,
          400,
          1100,
          674,
          1458,
          2341,
          1373,
          2344,
          1025,
          2232,
          1530,
          1881,
          1003,
          760,
          1346,
          3452,
          750,
          512,
          498,
          698,
          396,
          1302,
          594,
          1134,
          737,
          458,
          664,
          372,
          755,
          1244,
          440,
          871,
          1160,
          495,
          1989,
          858,
          437,
          688,
          841,
          717,
          847,
          1293,
          990,
          1189,
          1611,
          738,
          1514,
          1878,
          607,
          939,
          1045,
          1344,
          919,
          636,
          1989,
          757,
          1410,
          697,
          572,
          1052,
          2080,
          1016,
          1532,
          821,
          1064,
          1284,
          1377,
          1679,
          329,
          896,
          330,
          437,
          1166,
          2380,
          516,
          265,
          709,
          940,
          1406,
          889,
          828,
          1272,
          1251,
          1899,
          977,
          2614,
          879,
          4054,
          3240,
          1341,
          1096,
          341,
          3503,
          307,
          438,
          753,
          728,
          742,
          1175,
          392,
          1123,
          525,
          434,
          510,
          1249,
          1114,
          820,
          173,
          620,
          525,
          772,
          729,
          654,
          1604,
          2064,
          1216,
          1393,
          1119,
          2730,
          839,
          1045,
          614,
          559,
          1123,
          949,
          296,
          2175,
          1126,
          1060,
          571,
          582,
          543,
          910,
          647,
          605,
          887,
          1497,
          1957,
          655,
          552,
          781,
          1373,
          712,
          399,
          878,
          531,
          969,
          701,
          415,
          400,
          1258,
          427,
          1443,
          363,
          631,
          1239,
          583,
          276,
          353,
          839,
          738,
          1444,
          842,
          420,
          1532,
          2583,
          977,
          1584,
          2199,
          1685,
          3349,
          2015,
          1375,
          2814,
          1689,
          1586,
          1064,
          479,
          969,
          883,
          552,
          515,
          1182,
          2880,
          1521,
          304,
          1003,
          822,
          1162,
          516,
          832,
          595,
          949,
          494,
          1144,
          488,
          560,
          1383,
          760,
          816,
          1107,
          654,
          2157,
          4319,
          1073,
          1217,
          1516,
          1765,
          1734,
          743,
          535,
          855,
          1109,
          379,
          727,
          326,
          1220,
          570,
          2024,
          919,
          1844,
          547,
          340,
          371,
          654,
          1447,
          1079,
          1183,
          865,
          985,
          445,
          815,
          995,
          1954,
          885,
          1033,
          1364,
          306,
          853,
          515,
          1842,
          426,
          1435,
          861,
          465,
          885,
          1297,
          527,
          1272,
          356,
          1137,
          455,
          1291,
          887,
          931,
          870,
          1386,
          2452,
          1224,
          1348,
          1625,
          754,
          1305,
          829,
          1243,
          1735,
          2205,
          739,
          620,
          1501,
          756,
          362,
          839,
          1615,
          610,
          679,
          718,
          623,
          659,
          470,
          745,
          940,
          565,
          700,
          140,
          735,
          897,
          783,
          1064,
          1445,
          3847,
          1378,
          1471,
          700,
          326,
          856,
          1346,
          770,
          1822,
          1195,
          223,
          520,
          825,
          699,
          232,
          879,
          255,
          376,
          781,
          223,
          614,
          801,
          697,
          1323,
          5609,
          975,
          1632,
          1369,
          1366,
          643,
          705,
          327,
          192,
          660,
          541,
          430,
          907,
          613,
          2289,
          1632,
          2162,
          1720,
          1932,
          861,
          606,
          1397,
          1048,
          467,
          811,
          890,
          999,
          823,
          886,
          334,
          1292,
          3830,
          524,
          739,
          865,
          667,
          5901,
          494,
          487,
          481,
          1298,
          1075,
          1165,
          1102,
          981,
          749,
          1034,
          863,
          1246,
          1516,
          1336,
          456,
          914,
          609,
          992,
          1112,
          704,
          289,
          1158,
          545,
          736,
          427,
          493,
          415,
          802,
          1821,
          2470,
          1081,
          312,
          361,
          801,
          838,
          612,
          912,
          450,
          1002,
          1223,
          863,
          565,
          2888,
          1396,
          934,
          624,
          479,
          1422,
          660,
          719,
          1540,
          1854,
          758,
          1455,
          1001,
          1518,
          894,
          3076,
          446,
          1002,
          1199,
          951,
          11075,
          513,
          1202,
          1054,
          2938,
          440,
          1615,
          3836,
          643,
          973,
          836,
          1408,
          2398,
          1286,
          869,
          677,
          1057,
          657,
          956,
          1036,
          546,
          861,
          423,
          141,
          2133,
          1259,
          378,
          687,
          1164,
          590,
          863,
          1022,
          830,
          623,
          1039,
          646,
          1424,
          754,
          731,
          1102,
          1986,
          1879,
          1079,
          1745,
          381,
          215,
          1882,
          187,
          1195,
          1660,
          1851,
          1250,
          1451,
          606,
          736,
          646,
          1117,
          420,
          456,
          536,
          528,
          945,
          1068,
          998,
          1611,
          242,
          1207,
          403,
          694,
          1227,
          555,
          810,
          1401,
          360,
          266,
          716,
          868,
          574,
          766,
          1622,
          843,
          841,
          558,
          499,
          311,
          1522,
          1906,
          388,
          676,
          1679,
          1144,
          362,
          1101,
          1598,
          727,
          1376,
          1615,
          1389,
          1786,
          1190,
          527,
          1126,
          2078,
          1494,
          632,
          982,
          328,
          621,
          618,
          796,
          839,
          769,
          315,
          971,
          1578,
          386,
          837,
          1074,
          790,
          813,
          569,
          590,
          369,
          909,
          975,
          575,
          566,
          529,
          450,
          1673,
          901,
          1685,
          2448,
          435,
          539,
          981,
          106,
          981,
          744,
          206,
          1485,
          1148,
          1044,
          3164,
          934,
          1561,
          2970,
          545,
          533,
          659,
          1120,
          2937,
          501,
          544,
          468,
          513,
          1011,
          529,
          8401,
          583,
          2359,
          992,
          560,
          456,
          813,
          449,
          1120,
          762,
          888,
          654,
          914,
          106,
          386,
          557,
          1730,
          2040,
          1108,
          756,
          516,
          807,
          1736,
          2443,
          405,
          12626,
          1281,
          463,
          895,
          579,
          3183,
          531,
          1443,
          829,
          1092,
          628,
          659,
          1855,
          455,
          1369,
          1495,
          763,
          893,
          1209,
          1217,
          442,
          859,
          2066,
          810,
          870,
          1126,
          1206,
          515,
          341,
          953,
          6130,
          648,
          599,
          328,
          430,
          865,
          1026,
          1668,
          408,
          760,
          838,
          1281,
          1692,
          603,
          664,
          371,
          861,
          876,
          450,
          782,
          549,
          1093,
          1406,
          924,
          588,
          1042,
          2567,
          1231,
          725,
          674,
          792,
          1508,
          1131,
          951,
          3015,
          1053,
          5541,
          729,
          1210,
          792,
          3796,
          672,
          2693,
          4229,
          1300,
          1211,
          2399,
          3107,
          1943,
          740,
          2516,
          1334,
          369,
          515,
          573,
          456,
          923,
          1507,
          273,
          1052,
          2378,
          1041,
          1920,
          1163,
          1177,
          1111,
          1147,
          529,
          360,
          756,
          1259,
          2528,
          599,
          723,
          3278,
          1014,
          488,
          2453,
          2094,
          1894,
          451,
          658,
          1088,
          1722,
          537,
          665,
          562,
          1063,
          1172,
          1708,
          634,
          1656,
          240,
          649,
          401,
          3887,
          1712,
          836,
          556,
          5392,
          883,
          421,
          830,
          159,
          690,
          366,
          596,
          237,
          133,
          248,
          1175,
          926,
          614,
          501,
          335,
          316,
          125,
          353,
          714,
          753,
          2731,
          4056,
          685,
          1349,
          890,
          181,
          362,
          528,
          1672,
          13418,
          2529,
          8275,
          3124,
          810,
          735,
          1227,
          2853,
          840,
          426,
          1254,
          1103,
          279,
          606,
          1382,
          231,
          2985,
          501,
          961,
          2222,
          336,
          291,
          217,
          552,
          381,
          1170,
          174,
          1438,
          931,
          364,
          4384,
          2619,
          2726,
          638,
          954,
          465,
          2251,
          6163,
          2065,
          464,
          464,
          4840,
          1329,
          283,
          782,
          386,
          655,
          1791,
          554,
          1380,
          690,
          1400,
          1052,
          588,
          860,
          441,
          878,
          441,
          908,
          425,
          960,
          1334,
          588,
          636,
          1820,
          426,
          835,
          758,
          481,
          785,
          444,
          936,
          448,
          1180,
          455,
          784,
          651,
          2029,
          1196,
          443,
          865,
          1430,
          1639,
          457,
          1108,
          438,
          786,
          437,
          838,
          584,
          1725,
          461,
          757,
          481,
          806,
          784,
          428,
          2502,
          557,
          1137,
          906,
          480,
          412,
          930,
          960,
          809,
          383,
          399,
          533,
          1461,
          707,
          837,
          711,
          896,
          149,
          852,
          119,
          122,
          638,
          128,
          1030,
          447,
          325,
          739,
          1161,
          137,
          524,
          195,
          870,
          214,
          214,
          1374,
          116,
          250,
          113,
          119,
          312,
          122,
          317,
          366,
          280,
          306,
          2061,
          1891,
          195,
          443,
          794,
          109,
          2299,
          274,
          560,
          130,
          853,
          1266,
          1693,
          118,
          127,
          178,
          265,
          315,
          120,
          207,
          191,
          115,
          296,
          116,
          143,
          162,
          648,
          339,
          407,
          171,
          833,
          362,
          1001,
          313,
          1205,
          652,
          744,
          525,
          1228,
          456,
          696,
          658,
          506,
          256,
          1059,
          505,
          125,
          235,
          287,
          144,
          219,
          829,
          206,
          281,
          1016,
          644,
          449,
          682,
          102,
          122,
          1309,
          351,
          388,
          139,
          243,
          169,
          265,
          908,
          145,
          601,
          319,
          387,
          1321,
          2935,
          2637,
          242,
          359,
          2689,
          604,
          4204,
          835,
          1603,
          1291,
          954,
          1932,
          83,
          81,
          89,
          2104,
          83,
          2082,
          83,
          290,
          84,
          215,
          533,
          231,
          90,
          678,
          30,
          1097,
          30,
          30,
          30,
          30,
          30,
          268,
          30,
          145,
          293,
          164,
          152,
          154,
          139,
          141,
          157,
          156,
          146,
          159,
          138,
          145,
          143,
          151,
          143,
          154,
          154,
          145,
          155,
          143,
          142,
          158,
          177,
          137,
          142,
          159,
          3551,
          197,
          167,
          282,
          277,
          87,
          89,
          278,
          292,
          86,
          84,
          72,
          83,
          485,
          86,
          506,
          87,
          256,
          648,
          163,
          30,
          211,
          94,
          83,
          1360,
          965,
          85,
          87,
          86,
          92,
          92,
          474,
          81,
          81,
          86,
          81,
          84,
          240,
          353,
          78,
          280,
          93,
          143,
          452,
          548,
          515,
          307,
          147,
          479,
          189,
          159,
          145,
          131,
          320,
          180,
          505,
          337,
          160,
          265,
          548,
          130,
          515,
          353,
          431,
          193,
          452,
          182,
          94,
          701,
          1542,
          1267,
          251,
          105,
          138,
          174,
          142,
          149,
          412,
          184,
          193,
          353,
          179,
          452,
          479,
          179,
          264,
          287,
          431,
          548,
          265,
          175,
          505,
          337,
          515,
          252,
          141,
          209,
          1505,
          670,
          1378,
          230,
          83,
          439,
          88,
          170,
          73,
          89,
          214,
          154,
          117,
          123,
          92,
          239,
          89,
          172,
          83,
          30,
          81,
          193,
          92,
          30,
          277,
          93,
          83,
          85,
          88,
          125,
          739,
          84,
          81,
          84,
          227,
          80,
          78,
          92,
          204,
          83,
          479,
          501,
          85,
          202,
          93,
          78,
          452,
          137,
          300,
          153,
          266,
          80,
          431,
          255,
          457,
          85,
          80,
          83,
          94,
          79,
          168,
          149,
          150,
          85,
          281,
          240,
          353,
          83,
          81,
          81,
          88,
          73,
          83,
          505,
          80,
          187,
          337,
          87,
          515,
          83,
          548,
          74,
          93,
          832,
          284,
          1489,
          250,
          248,
          258,
          233,
          157,
          158,
          221,
          136,
          119,
          243,
          268,
          487,
          128,
          1238,
          139,
          148,
          1369,
          366,
          266,
          819,
          1275,
          174,
          334,
          401,
          435,
          3728,
          327,
          1261,
          594,
          266,
          162,
          1830,
          194,
          175,
          269,
          262,
          891,
          213,
          269,
          241,
          1483,
          477,
          197,
          159,
          135,
          146,
          159,
          540,
          161,
          302,
          169,
          282,
          307,
          151,
          123,
          285,
          259,
          1405,
          200,
          749,
          295,
          413,
          139,
          1721,
          244,
          266,
          275,
          248,
          200,
          394,
          5475,
          1539,
          1355,
          1731,
          402,
          164,
          566,
          578,
          140,
          956,
          214,
          263,
          151,
          268,
          172,
          925,
          170,
          233,
          153,
          189,
          164,
          166,
          230,
          178,
          168,
          1148,
          146,
          135,
          177,
          149,
          182,
          169,
          117,
          142,
          145,
          157,
          188,
          946,
          163,
          175,
          410,
          135,
          643,
          769,
          442,
          287,
          150,
          131,
          177,
          167,
          225,
          252,
          1798,
          233,
          156,
          341,
          215,
          372,
          416,
          497,
          245,
          506,
          223,
          210,
          411,
          475,
          1151,
          603,
          366,
          222,
          1101,
          506,
          289,
          166,
          423,
          157,
          213,
          650,
          468,
          290,
          485,
          1450,
          219,
          504,
          268,
          533,
          179,
          334,
          822,
          243,
          409,
          594,
          648,
          392,
          614,
          2084,
          629,
          474,
          184,
          97,
          183,
          141,
          183,
          191,
          145,
          138,
          1714,
          186,
          661,
          320,
          6398,
          1421,
          329,
          699,
          267,
          346,
          299,
          168,
          257,
          103,
          112,
          377,
          235,
          249,
          301,
          222,
          156,
          539,
          180,
          866,
          240,
          238,
          608,
          871,
          3872,
          7370,
          225,
          962,
          651,
          168,
          142,
          183,
          445,
          252,
          228,
          149,
          115,
          381,
          141,
          236,
          157,
          113,
          136,
          152,
          156,
          125,
          6446,
          299,
          823,
          234,
          279,
          1131,
          219,
          2333,
          619,
          606,
          170,
          223,
          189,
          242,
          149,
          133,
          144,
          281,
          157,
          274,
          365,
          131,
          162,
          161,
          128,
          172,
          210,
          151,
          144,
          152,
          139,
          121,
          136,
          148,
          6253,
          406,
          205,
          260,
          464,
          3341,
          8639,
          748,
          1327,
          298,
          3320,
          902,
          925,
          609,
          3023,
          493,
          892,
          601,
          1247,
          222,
          1634,
          994,
          1088,
          1222,
          805,
          544,
          1482,
          604,
          361,
          561,
          345,
          915,
          377,
          317,
          352,
          353,
          3312,
          1215,
          1131,
          981,
          766,
          363,
          247,
          546,
          1488,
          742,
          942,
          2271,
          503,
          469,
          4488,
          234,
          1383,
          416,
          375,
          507,
          801,
          1253,
          404,
          811,
          1288,
          974,
          275,
          979,
          1618,
          326,
          840,
          1313,
          989,
          487,
          387,
          2465,
          406,
          2394,
          638,
          3245,
          2809,
          1500,
          784,
          216,
          387,
          953,
          602,
          2403,
          661,
          2470,
          332,
          487,
          2513,
          2701,
          1375,
          541,
          186,
          2470,
          387,
          392,
          686,
          1235,
          3349,
          487,
          1663,
          871,
          1966,
          14544,
          624,
          632,
          16143,
          926,
          826,
          206,
          688,
          873,
          387,
          997,
          364,
          136,
          514,
          691,
          665,
          727,
          892,
          845,
          454,
          3235,
          332,
          687,
          256,
          224,
          249,
          454,
          582,
          224,
          1036,
          394,
          1291,
          492,
          2540,
          718,
          1377,
          61,
          554,
          485,
          454,
          454,
          2522,
          259,
          454,
          1039,
          801,
          1372,
          602,
          2999,
          15704,
          557,
          1016,
          820,
          551,
          979,
          186,
          520,
          957,
          873,
          886,
          1085,
          701,
          424,
          704,
          2567,
          1132,
          399,
          845,
          1500,
          1941,
          2688,
          120,
          332,
          1094,
          280,
          568,
          3876,
          584,
          586,
          566,
          355,
          812,
          1051,
          1341,
          269,
          1291,
          405,
          873,
          269,
          392,
          286,
          701,
          566,
          500,
          816,
          508,
          876,
          679,
          870,
          917,
          366,
          1278,
          1373,
          41,
          573,
          873,
          2573,
          922,
          672,
          204,
          1209,
          389,
          1362,
          1103,
          1090,
          42,
          561,
          677,
          879,
          3354,
          1365,
          2499,
          42,
          6094,
          1018,
          380,
          2099,
          936,
          566,
          991,
          872,
          2973,
          327,
          2448,
          364,
          332,
          1365,
          908,
          730,
          769,
          438,
          1346,
          845,
          989,
          839,
          677,
          17938,
          1346,
          1476,
          263,
          1195,
          847,
          1132,
          2973,
          291,
          902,
          1246,
          2142,
          240,
          1149,
          1392,
          18941,
          224,
          1346,
          2259,
          1304,
          528,
          901,
          528,
          522,
          828,
          2717,
          2257,
          1308,
          1002,
          3786,
          186,
          1240,
          705,
          1209,
          2281,
          2567,
          2940,
          1766,
          2852,
          186,
          1158,
          764,
          2675,
          674,
          951,
          2610,
          2774,
          1616,
          487,
          1230,
          1306,
          2973,
          2758,
          1780,
          2418,
          6744,
          1039,
          2657,
          808,
          1003,
          808,
          596,
          194,
          69860,
          605,
          4349,
          1177,
          585,
          9185,
          1392,
          393,
          2662,
          9196,
          9159,
          813,
          10290,
          10293,
          4691,
          515,
          1266,
          1266,
          160,
          894,
          1156,
          424,
          2983,
          808,
          812,
          3030,
          1687,
          375,
          3606,
          1132,
          1032,
          150,
          1795,
          2037,
          1913,
          1127,
          671,
          16266,
          2621,
          850,
          1437,
          3018,
          1729,
          41,
          574,
          4800,
          1195,
          1150,
          284,
          966,
          868,
          352,
          352,
          1746,
          487,
          476,
          998,
          1766,
          910,
          268,
          982,
          644,
          1,
          1003,
          939,
          1559,
          284,
          4173,
          1992,
          61,
          2189,
          7829,
          3668,
          3644,
          17374,
          159,
          773,
          300,
          160,
          164,
          375,
          375,
          375,
          3644,
          1,
          391,
          2973,
          3262,
          3262,
          3262,
          3262,
          583,
          1662,
          284,
          1046,
          1391,
          1737,
          1174,
          891,
          1520,
          434,
          4123,
          1699,
          146,
          675,
          306,
          339,
          2560,
          74,
          2519,
          880,
          2051,
          1132,
          1010,
          2923,
          190,
          2907,
          2683,
          15448,
          394,
          1520,
          1059,
          2051,
          339,
          922,
          899,
          852,
          8255,
          992,
          563,
          658,
          466,
          2151,
          1309,
          429,
          1792,
          3174,
          2051,
          1870,
          763,
          1236,
          864,
          722,
          1203,
          2223,
          2223,
          655,
          505,
          610,
          404,
          2458,
          907,
          272,
          469,
          1941,
          1249,
          1123,
          1446,
          2036,
          547,
          16561,
          268,
          164,
          1236,
          3206,
          929,
          1614,
          1339,
          689,
          830,
          964,
          1026,
          2458,
          199,
          1315,
          1013,
          401,
          15511,
          15411,
          1026,
          391,
          1505,
          8229,
          651,
          1166,
          2514,
          852,
          2303,
          364,
          879,
          1726,
          498,
          1562,
          585,
          718,
          406,
          430,
          495,
          581,
          2868,
          3001,
          580,
          936,
          2614,
          503,
          7156,
          1034,
          1198,
          113,
          675,
          2973,
          1228,
          321,
          961,
          687,
          3057,
          1416,
          2312,
          1614,
          852,
          3043,
          2466,
          480,
          332,
          1784,
          514,
          151,
          2659,
          1304,
          940,
          16295,
          915,
          1633,
          209,
          2738,
          200408,
          1015,
          1622,
          2780,
          2773,
          3272,
          974,
          1037,
          22067,
          1091,
          956,
          956,
          1470,
          2320,
          3261,
          561,
          468,
          864,
          4129,
          1981
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "coloraxis": {
         "colorbar": {
          "title": {
           "text": "Email Type (0 = Not Spam, 1 = Spam)"
          }
         },
         "colorscale": [
          [
           0,
           "#636EFA"
          ],
          [
           1,
           "#EF553B"
          ]
         ]
        },
        "legend": {
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#C8D4E3"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Interactive Scatter Plot of Email Length vs. Label"
        },
        "xaxis": {
         "anchor": "y",
         "categoryarray": [
          0,
          1
         ],
         "categoryorder": "array",
         "domain": [
          0,
          1
         ],
         "tickmode": "array",
         "ticktext": [
          "Not Spam",
          "Spam"
         ],
         "tickvals": [
          0,
          1
         ],
         "title": {
          "text": "Email Type (0 = Not Spam, 1 = Spam)"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Email Length (characters)"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "# Creating an interactive scatter plot using Plotly\n",
    "fig = px.scatter(\n",
    "    data,\n",
    "    x='label',\n",
    "    y='email_length',\n",
    "    color='label',\n",
    "    labels={'label': 'Email Type (0 = Not Spam, 1 = Spam)', 'email_length': 'Email Length (characters)'},\n",
    "    title='Interactive Scatter Plot of Email Length vs. Label',\n",
    "    color_continuous_scale=['#636EFA', '#EF553B'],\n",
    "    category_orders={\"label\": [0, 1]},\n",
    ")\n",
    "\n",
    "# Updating layout for better readability\n",
    "fig.update_layout(\n",
    "    xaxis=dict(\n",
    "        tickmode='array',\n",
    "        tickvals=[0, 1],\n",
    "        ticktext=['Not Spam', 'Spam']\n",
    "    ),\n",
    "    template='plotly_white'\n",
    ")\n",
    "\n",
    "# Display the plot\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.The dataset originally contained 2,500 \"Not Spam\" emails and 500 \"Spam\" emails. After removing a record with a missing value we have 2500 \"Not Spam\" and 499 \"Spam\" samples.\n",
    "2.Since the dataset is imbalanced with more \"Not Spam\" than \"Spam\" emails, we should consider splitting the data in a balanced manner to avoid bias in the model results.\n",
    "3.Regarding the distribution of email lengths, \"Spam\" emails include one with a particularly large length, while most have fewer than 999 characters. \"Not Spam\" emails have a higher count across the range of lengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Balance the dataset\n",
    "#Method -1 Undersampling\n",
    "#Method -2 Oversampling\n",
    "#class weight Adjustment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    499\n",
       "1    499\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "not_spam=df[df['label']==0]\n",
    "spam=df[df['label']==1]\n",
    "not_spam_downsample=resample(not_spam,replace=False,n_samples=len(spam),random_state=42)\n",
    "balanced_df_undersample=pd.concat([not_spam_downsample,spam])\n",
    "balanced_df_undersample=balanced_df_undersample.sample(frac=1,random_state=42).reset_index(drop=True)\n",
    "balanced_df_undersample['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imbalanced-learn\n",
      "  Downloading imbalanced_learn-0.12.4-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\workspace\\.venv\\lib\\site-packages (from imbalanced-learn) (2.1.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\workspace\\.venv\\lib\\site-packages (from imbalanced-learn) (1.14.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\workspace\\.venv\\lib\\site-packages (from imbalanced-learn) (1.5.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\workspace\\.venv\\lib\\site-packages (from imbalanced-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\workspace\\.venv\\lib\\site-packages (from imbalanced-learn) (3.5.0)\n",
      "Downloading imbalanced_learn-0.12.4-py3-none-any.whl (258 kB)\n",
      "Installing collected packages: imbalanced-learn\n",
      "Successfully installed imbalanced-learn-0.12.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution after SMOTE oversampling: {np.int64(0): np.int64(2500), np.int64(1): np.int64(2500)}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import numpy as np\n",
    "# Defining the feature and label columns\n",
    "X = df['email']\n",
    "y = df['label']\n",
    "\n",
    "# Converting the text data into numerical features using Count Vectorizer\n",
    "count_vectorizer = CountVectorizer(stop_words='english', max_features=5000)\n",
    "X_count = count_vectorizer.fit_transform(X)\n",
    "\n",
    "# Using SMOTE to oversample the minority class\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled_count, y_resampled_count = smote.fit_resample(X_count, y)\n",
    "\n",
    "# Displaying the distribution of resampled labels\n",
    "unique, counts = np.unique(y_resampled_count, return_counts=True)\n",
    "print(\"Distribution after SMOTE oversampling:\", dict(zip(unique, counts)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Undersampled Training Set Size: 698\n",
      "Undersampled Testing Set Size: 300\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_undersampled=balanced_df_undersample['email']\n",
    "y_undersampled=balanced_df_undersample['label']\n",
    "\n",
    "X_undersampled_count=count_vectorizer.fit_transform(X_undersampled)\n",
    "X_train_under,X_test_under,y_train_under,y_test_under=train_test_split(X_undersampled_count,y_undersampled,test_size=0.3,random_state=42)\n",
    "print(\"Undersampled Training Set Size:\", X_train_under.shape[0])\n",
    "print(\"Undersampled Testing Set Size:\", X_test_under.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE-Resampled Training Set Size: 3500\n",
      "SMOTE-Resampled Testing Set Size: 1500\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_smote, X_test_smote, y_train_smote, y_test_smote = train_test_split(X_resampled_count, y_resampled_count, test_size=0.3, random_state=42)\n",
    "print(\"SMOTE-Resampled Training Set Size:\", X_train_smote.shape[0])\n",
    "print(\"SMOTE-Resampled Testing Set Size:\", X_test_smote.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,BaggingClassifier,VotingClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import classification_report, accuracy_score, roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from tabulate import tabulate\n",
    "\n",
    "def train_and_evaluate_model(model, X_train, y_train, X_test, y_test, important_features=None):\n",
    "    \"\"\"\n",
    "    Trains and evaluates the given model using the specified training and testing data.\n",
    "\n",
    "    Parameters:\n",
    "    - model: The model to train (e.g., RandomForestClassifier).\n",
    "    - X_train: The training feature dataset.\n",
    "    - y_train: The training labels.\n",
    "    - X_test: The testing feature dataset.\n",
    "    - y_test: The testing labels.\n",
    "    - important_features: List of important features to use (default is None, use all features).\n",
    "\n",
    "    Returns:\n",
    "    - accuracy: Accuracy score of the model on the test set.\n",
    "    - report: Classification report for the model's predictions.\n",
    "    \"\"\"\n",
    "    # Use only the important features if provided\n",
    "    if important_features is not None:\n",
    "        X_train = X_train[important_features]\n",
    "        X_test = X_test[important_features]\n",
    "\n",
    "    # Convert sparse matrices to dense if necessary\n",
    "    if hasattr(X_train, 'toarray'):\n",
    "        X_train = X_train.toarray()\n",
    "    if hasattr(X_test, 'toarray'):\n",
    "        X_test = X_test.toarray()\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Evaluate model performance\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "\n",
    "    return accuracy, report\n",
    "\n",
    "def train_multiple_classifiers(X_train_under, y_train_under, X_test_under, y_test_under, \n",
    "                               X_train_smote, y_train_smote, X_test_smote, y_test_smote, important_features=None):\n",
    "    # List of models to train\n",
    "    models = [\n",
    "        (\"Random Forest\", RandomForestClassifier(random_state=42)),\n",
    "        (\"Decision Tree\", DecisionTreeClassifier(random_state=42)),\n",
    "        (\"Logistic Regression\", LogisticRegression(random_state=42)),\n",
    "        (\"K-Neighbors Classifier\", KNeighborsClassifier()),\n",
    "        (\"Gradient Boosting\", GradientBoostingClassifier(random_state=42)),\n",
    "        (\"Naive Bayes\", GaussianNB()),\n",
    "        (\"Support Vector Machine\", SVC(probability=True, random_state=42)),\n",
    "        (\"AdaBoost\", AdaBoostClassifier(random_state=42)),\n",
    "        (\"Bagging Classifier\", BaggingClassifier(random_state=42)),\n",
    "        (\"Voting Classifier\", VotingClassifier(estimators=[\n",
    "            ('lr', LogisticRegression(random_state=42)),\n",
    "            ('rf', RandomForestClassifier(random_state=42)),\n",
    "            ('gnb', GaussianNB())\n",
    "        ], voting='soft'))\n",
    "    ]\n",
    "\n",
    "    metrics_under = []\n",
    "    metrics_smote = []\n",
    "\n",
    "    # Train and evaluate each model on both undersampled and SMOTE-resampled datasets\n",
    "    for model_name, model in models:\n",
    "        print(f\"\\nTraining {model_name} on Undersampled Data...\")\n",
    "        accuracy_under, report_under = train_and_evaluate_model(model, X_train_under, y_train_under, X_test_under, y_test_under, important_features)\n",
    "        metrics_under.append((model_name, accuracy_under, report_under))\n",
    "\n",
    "        print(f\"\\nTraining {model_name} on SMOTE-Resampled Data...\")\n",
    "        accuracy_smote, report_smote = train_and_evaluate_model(model, X_train_smote, y_train_smote, X_test_smote, y_test_smote, important_features)\n",
    "        metrics_smote.append((model_name, accuracy_smote, report_smote))\n",
    "\n",
    "    # Display results in a tabular format for undersampled data\n",
    "    print(\"\\nResults for Undersampled Data:\")\n",
    "    print(tabulate(metrics_under, headers=[\"Model\", \"Accuracy\", \"Classification Report\"], tablefmt=\"pretty\", floatfmt=\".4f\"))\n",
    "\n",
    "    # Display results in a tabular format for SMOTE-resampled data\n",
    "    print(\"\\nResults for SMOTE-Resampled Data:\")\n",
    "    print(tabulate(metrics_smote, headers=[\"Model\", \"Accuracy\", \"Classification Report\"], tablefmt=\"pretty\", floatfmt=\".4f\"))\n",
    "\n",
    "    return metrics_under, metrics_smote\n",
    "\n",
    "# Example usage of the modified function\n",
    "# Assuming X_train_under, X_test_under, y_train_under, y_test_under are from the undersampled dataset\n",
    "# and X_train_smote, X_test_smote, y_train_smote, y_test_smote are from the SMOTE-resampled dataset\n",
    "\n",
    "# Uncomment and run this part once you have the required datasets\n",
    "# metrics_under, metrics_smote = train_multiple_classifiers(X_train_under, y_train_under, X_test_under, y_test_under,\n",
    "#                                                          X_train_smote, y_train_smote, X_test_smote, y_test_smote)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>email</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>date wed NUMBER aug NUMBER NUMBER NUMBER NUMB...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>martin a posted tassos papadopoulos the greek ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>man threatens explosion in moscow thursday aug...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>klez the virus that won t die already the most...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>in adding cream to spaghetti carbonara which ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>abc s good morning america ranks it the NUMBE...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>hyperlink hyperlink hyperlink let mortgage le...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>thank you for shopping with us gifts for all ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>the famous ebay marketing e course learn to s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>hello this is chinese traditional 子 件 NUMBER世...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2999 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  email  label\n",
       "0      date wed NUMBER aug NUMBER NUMBER NUMBER NUMB...      0\n",
       "1     martin a posted tassos papadopoulos the greek ...      0\n",
       "2     man threatens explosion in moscow thursday aug...      0\n",
       "3     klez the virus that won t die already the most...      0\n",
       "4      in adding cream to spaghetti carbonara which ...      0\n",
       "...                                                 ...    ...\n",
       "2995   abc s good morning america ranks it the NUMBE...      1\n",
       "2996   hyperlink hyperlink hyperlink let mortgage le...      1\n",
       "2997   thank you for shopping with us gifts for all ...      1\n",
       "2998   the famous ebay marketing e course learn to s...      1\n",
       "2999   hello this is chinese traditional 子 件 NUMBER世...      1\n",
       "\n",
       "[2999 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Random Forest on Undersampled Data...\n",
      "\n",
      "Training Random Forest on SMOTE-Resampled Data...\n",
      "\n",
      "Training Decision Tree on Undersampled Data...\n",
      "\n",
      "Training Decision Tree on SMOTE-Resampled Data...\n",
      "\n",
      "Training Logistic Regression on Undersampled Data...\n",
      "\n",
      "Training Logistic Regression on SMOTE-Resampled Data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\workspace\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training K-Neighbors Classifier on Undersampled Data...\n",
      "\n",
      "Training K-Neighbors Classifier on SMOTE-Resampled Data...\n",
      "\n",
      "Training Gradient Boosting on Undersampled Data...\n",
      "\n",
      "Training Gradient Boosting on SMOTE-Resampled Data...\n",
      "\n",
      "Training Naive Bayes on Undersampled Data...\n",
      "\n",
      "Training Naive Bayes on SMOTE-Resampled Data...\n",
      "\n",
      "Training Support Vector Machine on Undersampled Data...\n",
      "\n",
      "Training Support Vector Machine on SMOTE-Resampled Data...\n",
      "\n",
      "Training AdaBoost on Undersampled Data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\workspace\\.venv\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training AdaBoost on SMOTE-Resampled Data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\workspace\\.venv\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Bagging Classifier on Undersampled Data...\n",
      "\n",
      "Training Bagging Classifier on SMOTE-Resampled Data...\n",
      "\n",
      "Training Voting Classifier on Undersampled Data...\n",
      "\n",
      "Training Voting Classifier on SMOTE-Resampled Data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\workspace\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for Undersampled Data:\n",
      "+------------------------+--------------------+-------------------------------------------------------+\n",
      "|         Model          |      Accuracy      |                 Classification Report                 |\n",
      "+------------------------+--------------------+-------------------------------------------------------+\n",
      "|     Random Forest      | 0.9366666666666666 |        precision    recall  f1-score   support        |\n",
      "|                        |                    |                                                       |\n",
      "|                        |                    |            0       0.99      0.89      0.94       170 |\n",
      "|                        |                    |            1       0.88      0.99      0.93       130 |\n",
      "|                        |                    |                                                       |\n",
      "|                        |                    |     accuracy                           0.94       300 |\n",
      "|                        |                    |    macro avg       0.94      0.94      0.94       300 |\n",
      "|                        |                    | weighted avg       0.94      0.94      0.94       300 |\n",
      "|     Decision Tree      | 0.9033333333333333 |        precision    recall  f1-score   support        |\n",
      "|                        |                    |                                                       |\n",
      "|                        |                    |            0       0.94      0.88      0.91       170 |\n",
      "|                        |                    |            1       0.86      0.93      0.89       130 |\n",
      "|                        |                    |                                                       |\n",
      "|                        |                    |     accuracy                           0.90       300 |\n",
      "|                        |                    |    macro avg       0.90      0.91      0.90       300 |\n",
      "|                        |                    | weighted avg       0.91      0.90      0.90       300 |\n",
      "|  Logistic Regression   |        0.98        |        precision    recall  f1-score   support        |\n",
      "|                        |                    |                                                       |\n",
      "|                        |                    |            0       0.98      0.98      0.98       170 |\n",
      "|                        |                    |            1       0.98      0.98      0.98       130 |\n",
      "|                        |                    |                                                       |\n",
      "|                        |                    |     accuracy                           0.98       300 |\n",
      "|                        |                    |    macro avg       0.98      0.98      0.98       300 |\n",
      "|                        |                    | weighted avg       0.98      0.98      0.98       300 |\n",
      "| K-Neighbors Classifier |        0.76        |        precision    recall  f1-score   support        |\n",
      "|                        |                    |                                                       |\n",
      "|                        |                    |            0       0.79      0.79      0.79       170 |\n",
      "|                        |                    |            1       0.72      0.72      0.72       130 |\n",
      "|                        |                    |                                                       |\n",
      "|                        |                    |     accuracy                           0.76       300 |\n",
      "|                        |                    |    macro avg       0.76      0.76      0.76       300 |\n",
      "|                        |                    | weighted avg       0.76      0.76      0.76       300 |\n",
      "|   Gradient Boosting    | 0.9666666666666667 |        precision    recall  f1-score   support        |\n",
      "|                        |                    |                                                       |\n",
      "|                        |                    |            0       0.98      0.96      0.97       170 |\n",
      "|                        |                    |            1       0.95      0.97      0.96       130 |\n",
      "|                        |                    |                                                       |\n",
      "|                        |                    |     accuracy                           0.97       300 |\n",
      "|                        |                    |    macro avg       0.97      0.97      0.97       300 |\n",
      "|                        |                    | weighted avg       0.97      0.97      0.97       300 |\n",
      "|      Naive Bayes       | 0.8833333333333333 |        precision    recall  f1-score   support        |\n",
      "|                        |                    |                                                       |\n",
      "|                        |                    |            0       0.91      0.88      0.90       170 |\n",
      "|                        |                    |            1       0.85      0.88      0.87       130 |\n",
      "|                        |                    |                                                       |\n",
      "|                        |                    |     accuracy                           0.88       300 |\n",
      "|                        |                    |    macro avg       0.88      0.88      0.88       300 |\n",
      "|                        |                    | weighted avg       0.88      0.88      0.88       300 |\n",
      "| Support Vector Machine | 0.8833333333333333 |        precision    recall  f1-score   support        |\n",
      "|                        |                    |                                                       |\n",
      "|                        |                    |            0       0.84      0.98      0.91       170 |\n",
      "|                        |                    |            1       0.97      0.75      0.85       130 |\n",
      "|                        |                    |                                                       |\n",
      "|                        |                    |     accuracy                           0.88       300 |\n",
      "|                        |                    |    macro avg       0.90      0.87      0.88       300 |\n",
      "|                        |                    | weighted avg       0.90      0.88      0.88       300 |\n",
      "|        AdaBoost        | 0.9633333333333334 |        precision    recall  f1-score   support        |\n",
      "|                        |                    |                                                       |\n",
      "|                        |                    |            0       0.98      0.95      0.97       170 |\n",
      "|                        |                    |            1       0.94      0.98      0.96       130 |\n",
      "|                        |                    |                                                       |\n",
      "|                        |                    |     accuracy                           0.96       300 |\n",
      "|                        |                    |    macro avg       0.96      0.96      0.96       300 |\n",
      "|                        |                    | weighted avg       0.96      0.96      0.96       300 |\n",
      "|   Bagging Classifier   | 0.9566666666666667 |        precision    recall  f1-score   support        |\n",
      "|                        |                    |                                                       |\n",
      "|                        |                    |            0       0.98      0.95      0.96       170 |\n",
      "|                        |                    |            1       0.93      0.97      0.95       130 |\n",
      "|                        |                    |                                                       |\n",
      "|                        |                    |     accuracy                           0.96       300 |\n",
      "|                        |                    |    macro avg       0.95      0.96      0.96       300 |\n",
      "|                        |                    | weighted avg       0.96      0.96      0.96       300 |\n",
      "|   Voting Classifier    |        0.96        |        precision    recall  f1-score   support        |\n",
      "|                        |                    |                                                       |\n",
      "|                        |                    |            0       0.97      0.96      0.96       170 |\n",
      "|                        |                    |            1       0.95      0.96      0.95       130 |\n",
      "|                        |                    |                                                       |\n",
      "|                        |                    |     accuracy                           0.96       300 |\n",
      "|                        |                    |    macro avg       0.96      0.96      0.96       300 |\n",
      "|                        |                    | weighted avg       0.96      0.96      0.96       300 |\n",
      "+------------------------+--------------------+-------------------------------------------------------+\n",
      "\n",
      "Results for SMOTE-Resampled Data:\n",
      "+------------------------+--------------------+-------------------------------------------------------+\n",
      "|         Model          |      Accuracy      |                 Classification Report                 |\n",
      "+------------------------+--------------------+-------------------------------------------------------+\n",
      "|     Random Forest      | 0.9833333333333333 |        precision    recall  f1-score   support        |\n",
      "|                        |                    |                                                       |\n",
      "|                        |                    |            0       1.00      0.97      0.98       768 |\n",
      "|                        |                    |            1       0.97      1.00      0.98       732 |\n",
      "|                        |                    |                                                       |\n",
      "|                        |                    |     accuracy                           0.98      1500 |\n",
      "|                        |                    |    macro avg       0.98      0.98      0.98      1500 |\n",
      "|                        |                    | weighted avg       0.98      0.98      0.98      1500 |\n",
      "|     Decision Tree      | 0.9666666666666667 |        precision    recall  f1-score   support        |\n",
      "|                        |                    |                                                       |\n",
      "|                        |                    |            0       0.99      0.95      0.97       768 |\n",
      "|                        |                    |            1       0.95      0.99      0.97       732 |\n",
      "|                        |                    |                                                       |\n",
      "|                        |                    |     accuracy                           0.97      1500 |\n",
      "|                        |                    |    macro avg       0.97      0.97      0.97      1500 |\n",
      "|                        |                    | weighted avg       0.97      0.97      0.97      1500 |\n",
      "|  Logistic Regression   | 0.9833333333333333 |        precision    recall  f1-score   support        |\n",
      "|                        |                    |                                                       |\n",
      "|                        |                    |            0       1.00      0.97      0.98       768 |\n",
      "|                        |                    |            1       0.97      1.00      0.98       732 |\n",
      "|                        |                    |                                                       |\n",
      "|                        |                    |     accuracy                           0.98      1500 |\n",
      "|                        |                    |    macro avg       0.98      0.98      0.98      1500 |\n",
      "|                        |                    | weighted avg       0.98      0.98      0.98      1500 |\n",
      "| K-Neighbors Classifier |       0.746        |        precision    recall  f1-score   support        |\n",
      "|                        |                    |                                                       |\n",
      "|                        |                    |            0       1.00      0.50      0.67       768 |\n",
      "|                        |                    |            1       0.66      1.00      0.79       732 |\n",
      "|                        |                    |                                                       |\n",
      "|                        |                    |     accuracy                           0.75      1500 |\n",
      "|                        |                    |    macro avg       0.83      0.75      0.73      1500 |\n",
      "|                        |                    | weighted avg       0.83      0.75      0.73      1500 |\n",
      "|   Gradient Boosting    | 0.9653333333333334 |        precision    recall  f1-score   support        |\n",
      "|                        |                    |                                                       |\n",
      "|                        |                    |            0       1.00      0.94      0.97       768 |\n",
      "|                        |                    |            1       0.94      1.00      0.97       732 |\n",
      "|                        |                    |                                                       |\n",
      "|                        |                    |     accuracy                           0.97      1500 |\n",
      "|                        |                    |    macro avg       0.97      0.97      0.97      1500 |\n",
      "|                        |                    | weighted avg       0.97      0.97      0.97      1500 |\n",
      "|      Naive Bayes       | 0.9646666666666667 |        precision    recall  f1-score   support        |\n",
      "|                        |                    |                                                       |\n",
      "|                        |                    |            0       0.96      0.97      0.97       768 |\n",
      "|                        |                    |            1       0.96      0.96      0.96       732 |\n",
      "|                        |                    |                                                       |\n",
      "|                        |                    |     accuracy                           0.96      1500 |\n",
      "|                        |                    |    macro avg       0.96      0.96      0.96      1500 |\n",
      "|                        |                    | weighted avg       0.96      0.96      0.96      1500 |\n",
      "| Support Vector Machine | 0.9413333333333334 |        precision    recall  f1-score   support        |\n",
      "|                        |                    |                                                       |\n",
      "|                        |                    |            0       0.90      0.99      0.95       768 |\n",
      "|                        |                    |            1       0.99      0.89      0.94       732 |\n",
      "|                        |                    |                                                       |\n",
      "|                        |                    |     accuracy                           0.94      1500 |\n",
      "|                        |                    |    macro avg       0.95      0.94      0.94      1500 |\n",
      "|                        |                    | weighted avg       0.95      0.94      0.94      1500 |\n",
      "|        AdaBoost        |        0.97        |        precision    recall  f1-score   support        |\n",
      "|                        |                    |                                                       |\n",
      "|                        |                    |            0       0.99      0.95      0.97       768 |\n",
      "|                        |                    |            1       0.95      0.99      0.97       732 |\n",
      "|                        |                    |                                                       |\n",
      "|                        |                    |     accuracy                           0.97      1500 |\n",
      "|                        |                    |    macro avg       0.97      0.97      0.97      1500 |\n",
      "|                        |                    | weighted avg       0.97      0.97      0.97      1500 |\n",
      "|   Bagging Classifier   | 0.9706666666666667 |        precision    recall  f1-score   support        |\n",
      "|                        |                    |                                                       |\n",
      "|                        |                    |            0       0.99      0.95      0.97       768 |\n",
      "|                        |                    |            1       0.95      0.99      0.97       732 |\n",
      "|                        |                    |                                                       |\n",
      "|                        |                    |     accuracy                           0.97      1500 |\n",
      "|                        |                    |    macro avg       0.97      0.97      0.97      1500 |\n",
      "|                        |                    | weighted avg       0.97      0.97      0.97      1500 |\n",
      "|   Voting Classifier    | 0.9926666666666667 |        precision    recall  f1-score   support        |\n",
      "|                        |                    |                                                       |\n",
      "|                        |                    |            0       1.00      0.99      0.99       768 |\n",
      "|                        |                    |            1       0.99      1.00      0.99       732 |\n",
      "|                        |                    |                                                       |\n",
      "|                        |                    |     accuracy                           0.99      1500 |\n",
      "|                        |                    |    macro avg       0.99      0.99      0.99      1500 |\n",
      "|                        |                    | weighted avg       0.99      0.99      0.99      1500 |\n",
      "+------------------------+--------------------+-------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example usage of the modified function\n",
    "# Assuming X_train_under, X_test_under, y_train_under, y_test_under are from the undersampled dataset\n",
    "# and X_train_smote, X_test_smote, y_train_smote, y_test_smote are from the SMOTE-resampled dataset\n",
    "\n",
    "# Uncomment and run this part once you have the required datasets\n",
    "metrics_under, metrics_smote = train_multiple_classifiers(X_train_under, y_train_under, X_test_under, y_test_under,\n",
    "                                                       X_train_smote, y_train_smote, X_test_smote, y_test_smote)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the result and accuracy cleary indicates SMOTE + RandomForest,Logistic Regression\n",
    "Voting Classifier - 99%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import json\n",
    "def perform_hyperparameter_tuning(X_train, y_train, model_names=None):\n",
    "    # Convert multilabel y_train to multiclass only for models that require 1D targets\n",
    "    if model_names is None:\n",
    "        model_names = [\"Random Forest\", \"Decision Tree\", \"Logistic Regression\", \"K-Neighbors Classifier\", \"Gradient Boosting\", \"Support Vector Machine\", \"Naive Bayes\", \"AdaBoost\", \"Bagging Classifier\"]\n",
    "\n",
    "    models_requiring_1d = [\"Logistic Regression\", \"Decision Tree\", \"Gradient Boosting\", \"Support Vector Machine\", \"Naive Bayes\", \"AdaBoost\", \"Bagging Classifier\"]\n",
    "\n",
    " \n",
    "    # Convert sparse matrices to dense if necessary\n",
    "    if hasattr(X_train, 'toarray'):\n",
    "        X_train = X_train.toarray()\n",
    "        \n",
    "    # Hyperparameter grid for each model\n",
    "    param_grids = {\n",
    "        \"Random Forest\": {\n",
    "            \"n_estimators\": [50, 100, 150],\n",
    "            \"max_depth\": [None, 10, 20],\n",
    "            \"min_samples_split\": [2, 5, 10],\n",
    "            \"min_samples_leaf\": [1, 2, 4],\n",
    "            \"bootstrap\": [True, False]\n",
    "        },\n",
    "        \"Decision Tree\": {\n",
    "            \"criterion\": [\"gini\", \"entropy\"],\n",
    "            \"max_depth\": [None, 10, 20],\n",
    "            \"min_samples_split\": [2, 5, 10],\n",
    "            \"min_samples_leaf\": [1, 2, 4]\n",
    "        },\n",
    "        \"Logistic Regression\": {\n",
    "            \"penalty\": [\"l1\", \"l2\"],\n",
    "            \"C\": [0.01, 0.1, 1, 10],\n",
    "            \"solver\": [\"liblinear\", \"saga\"],\n",
    "            \"max_iter\": [100, 500, 1000]\n",
    "        },\n",
    "        \"K-Neighbors Classifier\": {\n",
    "            \"n_neighbors\": [3, 5, 7, 9],\n",
    "            \"weights\": [\"uniform\", \"distance\"],\n",
    "            \"algorithm\": [\"auto\", \"ball_tree\", \"kd_tree\", \"brute\"],\n",
    "            \"p\": [1, 2]\n",
    "        },\n",
    "        \"Gradient Boosting\": {\n",
    "            \"n_estimators\": [50, 100, 150],\n",
    "            \"learning_rate\": [0.01, 0.1, 0.2],\n",
    "            \"max_depth\": [3, 5, 7],\n",
    "            \"min_samples_split\": [2, 5, 10],\n",
    "            \"min_samples_leaf\": [1, 2, 4]\n",
    "        },\n",
    "        \"Support Vector Machine\": {\n",
    "            \"C\": [0.1, 1, 10, 100],\n",
    "            \"kernel\": [\"linear\", \"rbf\", \"poly\", \"sigmoid\"],\n",
    "            \"gamma\": [\"scale\", \"auto\"],\n",
    "            \"probability\": [True]\n",
    "        },\n",
    "        \"Naive Bayes\": {\n",
    "            \"var_smoothing\": [1e-9, 1e-8, 1e-7, 1e-6]\n",
    "        },\n",
    "        \"AdaBoost\": {\n",
    "            \"n_estimators\": [50, 100, 150],\n",
    "            \"learning_rate\": [0.01, 0.1, 1]\n",
    "        },\n",
    "        \"Bagging Classifier\": {\n",
    "            \"n_estimators\": [10, 50, 100],\n",
    "            \"max_samples\": [0.5, 0.7, 1.0],\n",
    "            \"bootstrap\": [True, False]\n",
    "        },\n",
    "         \"Voting Classifier\": {\n",
    "            \"voting\": [\"hard\", \"soft\"],\n",
    "            \"weights\": [[1, 1, 1], [2, 1, 1], [1, 2, 1]],\n",
    "            \"estimators\": [[('lr', LogisticRegression(random_state=42)), ('rf', RandomForestClassifier(random_state=42)), ('gnb', GaussianNB())]]\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Models to tune\n",
    "    models = {\n",
    "        \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "        \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "        \"Logistic Regression\": LogisticRegression(random_state=42),\n",
    "        \"K-Neighbors Classifier\": KNeighborsClassifier(),\n",
    "        \"Support Vector Machine\": SVC(probability=True, random_state=42),\n",
    "        \"Naive Bayes\": GaussianNB(),\n",
    "        \"AdaBoost\": AdaBoostClassifier(random_state=42),\n",
    "        \"Bagging Classifier\": BaggingClassifier(random_state=42),\n",
    "        \"Voting Classifier\": VotingClassifier(estimators=[\n",
    "            ('lr', LogisticRegression(random_state=42)),\n",
    "            ('rf', RandomForestClassifier(random_state=42)),\n",
    "            ('gnb', GaussianNB())\n",
    "        ], voting='soft')\n",
    "    }\n",
    "\n",
    "    best_params = {}\n",
    "\n",
    "    # If model_names is not specified, tune all models\n",
    "    if model_names is None:\n",
    "        model_names = models.keys()\n",
    "\n",
    "    # Perform hyperparameter tuning for specified models\n",
    "    for model_name in model_names:\n",
    "        if model_name not in models:\n",
    "            print(f\"Model {model_name} is not recognized. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        model = models[model_name]\n",
    "        print(f\"\\nPerforming hyperparameter tuning for {model_name}...\")\n",
    "        grid_search = GridSearchCV(estimator=model, param_grid=param_grids[model_name], cv=3, n_jobs=-1, verbose=2)\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        best_params[model_name] = grid_search.best_params_\n",
    "        print(f\"Best parameters for {model_name}: {grid_search.best_params_}\")\n",
    "\n",
    "    # Save the best parameters to a JSON file\n",
    "    with open('best_model_params.json', 'w') as json_file:\n",
    "        json.dump(best_params, json_file, indent=4)\n",
    "\n",
    "    return best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performing hyperparameter tuning for Random Forest...\n",
      "Fitting 3 folds for each of 162 candidates, totalling 486 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\workspace\\.venv\\Lib\\site-packages\\numpy\\ma\\core.py:2881: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in cast\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Random Forest: {'bootstrap': False, 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 50}\n",
      "\n",
      "Performing hyperparameter tuning for Decision Tree...\n",
      "Fitting 3 folds for each of 54 candidates, totalling 162 fits\n",
      "Best parameters for Decision Tree: {'criterion': 'entropy', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "\n",
      "Performing hyperparameter tuning for Logistic Regression...\n",
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n",
      "Best parameters for Logistic Regression: {'C': 0.1, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "\n",
      "Performing hyperparameter tuning for K-Neighbors Classifier...\n",
      "Fitting 3 folds for each of 64 candidates, totalling 192 fits\n",
      "Best parameters for K-Neighbors Classifier: {'algorithm': 'auto', 'n_neighbors': 3, 'p': 2, 'weights': 'distance'}\n",
      "Model Gradient Boosting is not recognized. Skipping...\n",
      "\n",
      "Performing hyperparameter tuning for Support Vector Machine...\n",
      "Fitting 3 folds for each of 32 candidates, totalling 96 fits\n",
      "Best parameters for Support Vector Machine: {'C': 10, 'gamma': 'scale', 'kernel': 'rbf', 'probability': True}\n",
      "\n",
      "Performing hyperparameter tuning for Naive Bayes...\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "Best parameters for Naive Bayes: {'var_smoothing': 1e-07}\n",
      "\n",
      "Performing hyperparameter tuning for AdaBoost...\n",
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\workspace\\.venv\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for AdaBoost: {'learning_rate': 1, 'n_estimators': 150}\n",
      "\n",
      "Performing hyperparameter tuning for Bagging Classifier...\n",
      "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n",
      "Best parameters for Bagging Classifier: {'bootstrap': True, 'max_samples': 1.0, 'n_estimators': 10}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Random Forest': {'bootstrap': False,\n",
       "  'max_depth': None,\n",
       "  'min_samples_leaf': 1,\n",
       "  'min_samples_split': 10,\n",
       "  'n_estimators': 50},\n",
       " 'Decision Tree': {'criterion': 'entropy',\n",
       "  'max_depth': None,\n",
       "  'min_samples_leaf': 1,\n",
       "  'min_samples_split': 2},\n",
       " 'Logistic Regression': {'C': 0.1,\n",
       "  'max_iter': 100,\n",
       "  'penalty': 'l2',\n",
       "  'solver': 'liblinear'},\n",
       " 'K-Neighbors Classifier': {'algorithm': 'auto',\n",
       "  'n_neighbors': 3,\n",
       "  'p': 2,\n",
       "  'weights': 'distance'},\n",
       " 'Support Vector Machine': {'C': 10,\n",
       "  'gamma': 'scale',\n",
       "  'kernel': 'rbf',\n",
       "  'probability': True},\n",
       " 'Naive Bayes': {'var_smoothing': 1e-07},\n",
       " 'AdaBoost': {'learning_rate': 1, 'n_estimators': 150},\n",
       " 'Bagging Classifier': {'bootstrap': True,\n",
       "  'max_samples': 1.0,\n",
       "  'n_estimators': 10}}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perform_hyperparameter_tuning(X_train_smote,y_train_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_multiple_classifiers(X_train_under, y_train_under, X_test_under, y_test_under, \n",
    "                               X_train_smote, y_train_smote, X_test_smote, y_test_smote, important_features=None):\n",
    "    # List of models to train\n",
    "     # Load the best hyperparameters from JSON file\n",
    "    with open('best_model_params.json', 'r') as json_file:\n",
    "        best_params = json.load(json_file)\n",
    "    print(best_params)\n",
    "\n",
    "    models = [\n",
    "        (\"Random Forest\", RandomForestClassifier(**best_params.get(\"Random Forest\", {}),class_weight='balanced',random_state=42)),\n",
    "        (\"Decision Tree\", DecisionTreeClassifier(**best_params.get(\"Decision Tree\", {}),random_state=42)),\n",
    "        (\"Logistic Regression\", LogisticRegression(**best_params.get(\"Logistic Regression\", {}),class_weight='balanced',random_state=42)),\n",
    "        (\"K-Neighbors Classifier\", KNeighborsClassifier(**best_params.get(\"K-Neighbors Classifier\", {}))),\n",
    "        #(\"Gradient Boosting\", GradientBoostingClassifier(**best_params.get(\"Random Forest\", {}),random_state=42)),\n",
    "        (\"Naive Bayes\", GaussianNB()),\n",
    "        (\"Support Vector Machine\", SVC(**best_params.get(\"Support Vector Machine\", {}), random_state=42)),\n",
    "        (\"AdaBoost\", AdaBoostClassifier(**best_params.get(\"AdaBoost\", {}),random_state=42)),\n",
    "        (\"Bagging Classifier\", BaggingClassifier(**best_params.get(\"Bagging Classifier\", {}),random_state=42)),\n",
    "        (\"Voting Classifier\", VotingClassifier(estimators=[\n",
    "            ('lr', LogisticRegression(**best_params.get(\"Logistic Regression\", {}),random_state=42)),\n",
    "            ('rf', RandomForestClassifier(**best_params.get(\"Random Forest\", {}),random_state=42)),\n",
    "            ('gnb', GaussianNB())\n",
    "        ], voting='soft'))\n",
    "    ]\n",
    "\n",
    "    metrics_under = []\n",
    "    metrics_smote = []\n",
    "\n",
    "    # Train and evaluate each model on both undersampled and SMOTE-resampled datasets\n",
    "    for model_name, model in models:\n",
    "        print(f\"\\nTraining {model_name} on Undersampled Data...\")\n",
    "        accuracy_under, report_under = train_and_evaluate_model(model, X_train_under, y_train_under, X_test_under, y_test_under, important_features)\n",
    "        metrics_under.append((model_name, accuracy_under, report_under))\n",
    "\n",
    "        print(f\"\\nTraining {model_name} on SMOTE-Resampled Data...\")\n",
    "        accuracy_smote, report_smote = train_and_evaluate_model(model, X_train_smote, y_train_smote, X_test_smote, y_test_smote, important_features)\n",
    "        metrics_smote.append((model_name, accuracy_smote, report_smote))\n",
    "\n",
    "    # Display results in a tabular format for undersampled data\n",
    "    print(\"\\nResults for Undersampled Data:\")\n",
    "    print(tabulate(metrics_under, headers=[\"Model\", \"Accuracy\", \"Classification Report\"], tablefmt=\"pretty\", floatfmt=\".4f\"))\n",
    "\n",
    "    # Display results in a tabular format for SMOTE-resampled data\n",
    "    print(\"\\nResults for SMOTE-Resampled Data:\")\n",
    "    print(tabulate(metrics_smote, headers=[\"Model\", \"Accuracy\", \"Classification Report\"], tablefmt=\"pretty\", floatfmt=\".4f\"))\n",
    "\n",
    "    return metrics_under, metrics_smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Random Forest': {'bootstrap': False, 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 50}, 'Decision Tree': {'criterion': 'entropy', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2}, 'Logistic Regression': {'C': 0.1, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear'}, 'K-Neighbors Classifier': {'algorithm': 'auto', 'n_neighbors': 3, 'p': 2, 'weights': 'distance'}, 'Support Vector Machine': {'C': 10, 'gamma': 'scale', 'kernel': 'rbf', 'probability': True}, 'Naive Bayes': {'var_smoothing': 1e-07}, 'AdaBoost': {'learning_rate': 1, 'n_estimators': 150}, 'Bagging Classifier': {'bootstrap': True, 'max_samples': 1.0, 'n_estimators': 10}}\n",
      "\n",
      "Training Random Forest on Undersampled Data...\n",
      "\n",
      "Training Random Forest on SMOTE-Resampled Data...\n",
      "\n",
      "Training Decision Tree on Undersampled Data...\n",
      "\n",
      "Training Decision Tree on SMOTE-Resampled Data...\n",
      "\n",
      "Training Logistic Regression on Undersampled Data...\n",
      "\n",
      "Training Logistic Regression on SMOTE-Resampled Data...\n",
      "\n",
      "Training K-Neighbors Classifier on Undersampled Data...\n",
      "\n",
      "Training K-Neighbors Classifier on SMOTE-Resampled Data...\n",
      "\n",
      "Training Naive Bayes on Undersampled Data...\n",
      "\n",
      "Training Naive Bayes on SMOTE-Resampled Data...\n",
      "\n",
      "Training Support Vector Machine on Undersampled Data...\n",
      "\n",
      "Training Support Vector Machine on SMOTE-Resampled Data...\n",
      "\n",
      "Training AdaBoost on Undersampled Data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\workspace\\.venv\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training AdaBoost on SMOTE-Resampled Data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\workspace\\.venv\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Bagging Classifier on Undersampled Data...\n",
      "\n",
      "Training Bagging Classifier on SMOTE-Resampled Data...\n",
      "\n",
      "Training Voting Classifier on Undersampled Data...\n",
      "\n",
      "Training Voting Classifier on SMOTE-Resampled Data...\n",
      "\n",
      "Results for Undersampled Data:\n",
      "+------------------------+--------------------+-------------------------------------------------------+\n",
      "|         Model          |      Accuracy      |                 Classification Report                 |\n",
      "+------------------------+--------------------+-------------------------------------------------------+\n",
      "|     Random Forest      | 0.9666666666666667 |        precision    recall  f1-score   support        |\n",
      "|                        |                    |                                                       |\n",
      "|                        |                    |            0       0.99      0.95      0.97       170 |\n",
      "|                        |                    |            1       0.94      0.98      0.96       130 |\n",
      "|                        |                    |                                                       |\n",
      "|                        |                    |     accuracy                           0.97       300 |\n",
      "|                        |                    |    macro avg       0.96      0.97      0.97       300 |\n",
      "|                        |                    | weighted avg       0.97      0.97      0.97       300 |\n",
      "|     Decision Tree      |        0.92        |        precision    recall  f1-score   support        |\n",
      "|                        |                    |                                                       |\n",
      "|                        |                    |            0       0.96      0.90      0.93       170 |\n",
      "|                        |                    |            1       0.88      0.95      0.91       130 |\n",
      "|                        |                    |                                                       |\n",
      "|                        |                    |     accuracy                           0.92       300 |\n",
      "|                        |                    |    macro avg       0.92      0.92      0.92       300 |\n",
      "|                        |                    | weighted avg       0.92      0.92      0.92       300 |\n",
      "|  Logistic Regression   | 0.9766666666666667 |        precision    recall  f1-score   support        |\n",
      "|                        |                    |                                                       |\n",
      "|                        |                    |            0       0.97      0.99      0.98       170 |\n",
      "|                        |                    |            1       0.99      0.95      0.97       130 |\n",
      "|                        |                    |                                                       |\n",
      "|                        |                    |     accuracy                           0.98       300 |\n",
      "|                        |                    |    macro avg       0.98      0.97      0.98       300 |\n",
      "|                        |                    | weighted avg       0.98      0.98      0.98       300 |\n",
      "| K-Neighbors Classifier | 0.8033333333333333 |        precision    recall  f1-score   support        |\n",
      "|                        |                    |                                                       |\n",
      "|                        |                    |            0       0.87      0.76      0.82       170 |\n",
      "|                        |                    |            1       0.74      0.85      0.79       130 |\n",
      "|                        |                    |                                                       |\n",
      "|                        |                    |     accuracy                           0.80       300 |\n",
      "|                        |                    |    macro avg       0.80      0.81      0.80       300 |\n",
      "|                        |                    | weighted avg       0.81      0.80      0.80       300 |\n",
      "|      Naive Bayes       | 0.8833333333333333 |        precision    recall  f1-score   support        |\n",
      "|                        |                    |                                                       |\n",
      "|                        |                    |            0       0.91      0.88      0.90       170 |\n",
      "|                        |                    |            1       0.85      0.88      0.87       130 |\n",
      "|                        |                    |                                                       |\n",
      "|                        |                    |     accuracy                           0.88       300 |\n",
      "|                        |                    |    macro avg       0.88      0.88      0.88       300 |\n",
      "|                        |                    | weighted avg       0.88      0.88      0.88       300 |\n",
      "| Support Vector Machine | 0.9533333333333334 |        precision    recall  f1-score   support        |\n",
      "|                        |                    |                                                       |\n",
      "|                        |                    |            0       0.94      0.98      0.96       170 |\n",
      "|                        |                    |            1       0.97      0.92      0.94       130 |\n",
      "|                        |                    |                                                       |\n",
      "|                        |                    |     accuracy                           0.95       300 |\n",
      "|                        |                    |    macro avg       0.96      0.95      0.95       300 |\n",
      "|                        |                    | weighted avg       0.95      0.95      0.95       300 |\n",
      "|        AdaBoost        | 0.9466666666666667 |        precision    recall  f1-score   support        |\n",
      "|                        |                    |                                                       |\n",
      "|                        |                    |            0       0.99      0.91      0.95       170 |\n",
      "|                        |                    |            1       0.90      0.99      0.94       130 |\n",
      "|                        |                    |                                                       |\n",
      "|                        |                    |     accuracy                           0.95       300 |\n",
      "|                        |                    |    macro avg       0.94      0.95      0.95       300 |\n",
      "|                        |                    | weighted avg       0.95      0.95      0.95       300 |\n",
      "|   Bagging Classifier   | 0.9566666666666667 |        precision    recall  f1-score   support        |\n",
      "|                        |                    |                                                       |\n",
      "|                        |                    |            0       0.98      0.95      0.96       170 |\n",
      "|                        |                    |            1       0.93      0.97      0.95       130 |\n",
      "|                        |                    |                                                       |\n",
      "|                        |                    |     accuracy                           0.96       300 |\n",
      "|                        |                    |    macro avg       0.95      0.96      0.96       300 |\n",
      "|                        |                    | weighted avg       0.96      0.96      0.96       300 |\n",
      "|   Voting Classifier    | 0.9533333333333334 |        precision    recall  f1-score   support        |\n",
      "|                        |                    |                                                       |\n",
      "|                        |                    |            0       0.96      0.96      0.96       170 |\n",
      "|                        |                    |            1       0.95      0.95      0.95       130 |\n",
      "|                        |                    |                                                       |\n",
      "|                        |                    |     accuracy                           0.95       300 |\n",
      "|                        |                    |    macro avg       0.95      0.95      0.95       300 |\n",
      "|                        |                    | weighted avg       0.95      0.95      0.95       300 |\n",
      "+------------------------+--------------------+-------------------------------------------------------+\n",
      "\n",
      "Results for SMOTE-Resampled Data:\n",
      "+------------------------+--------------------+-------------------------------------------------------+\n",
      "|         Model          |      Accuracy      |                 Classification Report                 |\n",
      "+------------------------+--------------------+-------------------------------------------------------+\n",
      "|     Random Forest      | 0.9833333333333333 |        precision    recall  f1-score   support        |\n",
      "|                        |                    |                                                       |\n",
      "|                        |                    |            0       0.99      0.97      0.98       768 |\n",
      "|                        |                    |            1       0.97      0.99      0.98       732 |\n",
      "|                        |                    |                                                       |\n",
      "|                        |                    |     accuracy                           0.98      1500 |\n",
      "|                        |                    |    macro avg       0.98      0.98      0.98      1500 |\n",
      "|                        |                    | weighted avg       0.98      0.98      0.98      1500 |\n",
      "|     Decision Tree      |       0.966        |        precision    recall  f1-score   support        |\n",
      "|                        |                    |                                                       |\n",
      "|                        |                    |            0       0.99      0.95      0.97       768 |\n",
      "|                        |                    |            1       0.95      0.99      0.97       732 |\n",
      "|                        |                    |                                                       |\n",
      "|                        |                    |     accuracy                           0.97      1500 |\n",
      "|                        |                    |    macro avg       0.97      0.97      0.97      1500 |\n",
      "|                        |                    | weighted avg       0.97      0.97      0.97      1500 |\n",
      "|  Logistic Regression   | 0.9873333333333333 |        precision    recall  f1-score   support        |\n",
      "|                        |                    |                                                       |\n",
      "|                        |                    |            0       1.00      0.98      0.99       768 |\n",
      "|                        |                    |            1       0.97      1.00      0.99       732 |\n",
      "|                        |                    |                                                       |\n",
      "|                        |                    |     accuracy                           0.99      1500 |\n",
      "|                        |                    |    macro avg       0.99      0.99      0.99      1500 |\n",
      "|                        |                    | weighted avg       0.99      0.99      0.99      1500 |\n",
      "| K-Neighbors Classifier | 0.7913333333333333 |        precision    recall  f1-score   support        |\n",
      "|                        |                    |                                                       |\n",
      "|                        |                    |            0       1.00      0.59      0.74       768 |\n",
      "|                        |                    |            1       0.70      1.00      0.82       732 |\n",
      "|                        |                    |                                                       |\n",
      "|                        |                    |     accuracy                           0.79      1500 |\n",
      "|                        |                    |    macro avg       0.85      0.80      0.78      1500 |\n",
      "|                        |                    | weighted avg       0.85      0.79      0.78      1500 |\n",
      "|      Naive Bayes       | 0.9646666666666667 |        precision    recall  f1-score   support        |\n",
      "|                        |                    |                                                       |\n",
      "|                        |                    |            0       0.96      0.97      0.97       768 |\n",
      "|                        |                    |            1       0.96      0.96      0.96       732 |\n",
      "|                        |                    |                                                       |\n",
      "|                        |                    |     accuracy                           0.96      1500 |\n",
      "|                        |                    |    macro avg       0.96      0.96      0.96      1500 |\n",
      "|                        |                    | weighted avg       0.96      0.96      0.96      1500 |\n",
      "| Support Vector Machine | 0.9793333333333333 |        precision    recall  f1-score   support        |\n",
      "|                        |                    |                                                       |\n",
      "|                        |                    |            0       1.00      0.96      0.98       768 |\n",
      "|                        |                    |            1       0.96      1.00      0.98       732 |\n",
      "|                        |                    |                                                       |\n",
      "|                        |                    |     accuracy                           0.98      1500 |\n",
      "|                        |                    |    macro avg       0.98      0.98      0.98      1500 |\n",
      "|                        |                    | weighted avg       0.98      0.98      0.98      1500 |\n",
      "|        AdaBoost        | 0.9733333333333334 |        precision    recall  f1-score   support        |\n",
      "|                        |                    |                                                       |\n",
      "|                        |                    |            0       0.99      0.95      0.97       768 |\n",
      "|                        |                    |            1       0.95      0.99      0.97       732 |\n",
      "|                        |                    |                                                       |\n",
      "|                        |                    |     accuracy                           0.97      1500 |\n",
      "|                        |                    |    macro avg       0.97      0.97      0.97      1500 |\n",
      "|                        |                    | weighted avg       0.97      0.97      0.97      1500 |\n",
      "|   Bagging Classifier   | 0.9706666666666667 |        precision    recall  f1-score   support        |\n",
      "|                        |                    |                                                       |\n",
      "|                        |                    |            0       0.99      0.95      0.97       768 |\n",
      "|                        |                    |            1       0.95      0.99      0.97       732 |\n",
      "|                        |                    |                                                       |\n",
      "|                        |                    |     accuracy                           0.97      1500 |\n",
      "|                        |                    |    macro avg       0.97      0.97      0.97      1500 |\n",
      "|                        |                    | weighted avg       0.97      0.97      0.97      1500 |\n",
      "|   Voting Classifier    | 0.9926666666666667 |        precision    recall  f1-score   support        |\n",
      "|                        |                    |                                                       |\n",
      "|                        |                    |            0       0.99      0.99      0.99       768 |\n",
      "|                        |                    |            1       0.99      0.99      0.99       732 |\n",
      "|                        |                    |                                                       |\n",
      "|                        |                    |     accuracy                           0.99      1500 |\n",
      "|                        |                    |    macro avg       0.99      0.99      0.99      1500 |\n",
      "|                        |                    | weighted avg       0.99      0.99      0.99      1500 |\n",
      "+------------------------+--------------------+-------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Uncomment and run this part once you have the required datasets\n",
    "metrics_under, metrics_smote = train_multiple_classifiers(X_train_under, y_train_under, X_test_under, y_test_under,\n",
    "                                                       X_train_smote, y_train_smote, X_test_smote, y_test_smote)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "def plot_learning_curve(model, X, y, model_name, cv=5, train_sizes=np.linspace(0.1, 1.0, 5)):\n",
    "    \"\"\"\n",
    "    Plots the learning curve for a given model.\n",
    "\n",
    "    Parameters:\n",
    "    - model: The model to train.\n",
    "    - X: Feature dataset.\n",
    "    - y: Labels.\n",
    "    - model_name: Name of the model (used for plotting).\n",
    "    - cv: Number of folds in cross-validation (default is 5).\n",
    "    - train_sizes: Array of training set sizes (default is np.linspace(0.1, 1.0, 5)).\n",
    "    \n",
    "    \"\"\"\n",
    "        # Convert sparse matrices to dense if necessary\n",
    "    if hasattr(X, 'toarray'):\n",
    "        X = X.toarray()\n",
    "    train_sizes, train_scores, val_scores = learning_curve(model, X, y, cv=cv, train_sizes=train_sizes, n_jobs=-1, scoring='accuracy')\n",
    "    \n",
    "\n",
    "    # Calculate mean and standard deviation\n",
    "    train_mean = np.mean(train_scores, axis=1)\n",
    "    train_std = np.std(train_scores, axis=1)\n",
    "    val_mean = np.mean(val_scores, axis=1)\n",
    "    val_std = np.std(val_scores, axis=1)\n",
    "\n",
    "    # Create interactive learning curve plot using Plotly\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=train_sizes, y=train_mean,\n",
    "        mode='lines',\n",
    "        name='Training Score',\n",
    "        line=dict(color='red'),\n",
    "        fill='tonexty',\n",
    "        fillcolor='rgba(255, 0, 0, 0.1)',\n",
    "        error_y=dict(type='data', array=train_std, visible=True)\n",
    "    ))\n",
    "    \n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=train_sizes, y=val_mean,\n",
    "        mode='lines',\n",
    "        name='Validation Score',\n",
    "        line=dict(color='green'),\n",
    "        fill='tonexty',\n",
    "        fillcolor='rgba(0, 255, 0, 0.1)',\n",
    "        error_y=dict(type='data', array=val_std, visible=True)\n",
    "    ))\n",
    "    \n",
    "    # Update layout for better visualization\n",
    "    fig.update_layout(\n",
    "        title=f'Learning Curve for {model_name}',\n",
    "        xaxis_title='Training Set Size',\n",
    "        yaxis_title='Accuracy Score',\n",
    "        template='plotly_white',\n",
    "        legend=dict(x=0.02, y=0.98),\n",
    "        xaxis=dict(showgrid=True),\n",
    "        yaxis=dict(showgrid=True)\n",
    "    )\n",
    "\n",
    "    # Show interactive plot\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Random Forest': {'bootstrap': False, 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 50}, 'Decision Tree': {'criterion': 'entropy', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2}, 'Logistic Regression': {'C': 0.1, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear'}, 'K-Neighbors Classifier': {'algorithm': 'auto', 'n_neighbors': 3, 'p': 2, 'weights': 'distance'}, 'Support Vector Machine': {'C': 10, 'gamma': 'scale', 'kernel': 'rbf', 'probability': True}, 'Naive Bayes': {'var_smoothing': 1e-07}, 'AdaBoost': {'learning_rate': 1, 'n_estimators': 150}, 'Bagging Classifier': {'bootstrap': True, 'max_samples': 1.0, 'n_estimators': 10}}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "with open('best_model_params.json', 'r') as json_file:\n",
    "    best_params = json.load(json_file)\n",
    "    print(best_params)\n",
    "\n",
    "\n",
    " #(\"Random Forest\", RandomForestClassifier(**best_params.get(\"Random Forest\", {}),random_state=42)),\n",
    "  #      (\"Decision Tree\", DecisionTreeClassifier(**best_params.get(\"Decision Tree\", {}),random_state=42)),\n",
    "   #     (\"Logistic Regression\", LogisticRegression(**best_params.get(\"Logistic Regression\", {}),random_state=42)),\n",
    "     #   (\"K-Neighbors Classifier\", KNeighborsClassifier(**best_params.get(\"K-Neighbors Classifier\", {}))),   \n",
    "RandomForestClassifier_1=RandomForestClassifier(**best_params.get(\"Random Forest\", {}),random_state=42)\n",
    "\n",
    "\n",
    "# Assuming X and y are your dataset and labels\n",
    "def example_plot_voting_learning_curve(X, y):\n",
    "    plot_learning_curve(RandomForestClassifier_1, X, y, model_name=\"Random Forest\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "error_y": {
          "array": [
           0.015714285714285705,
           0.005714285714285738,
           0.003518497969907538,
           0.008515251216553813,
           0.002130919127168029
          ],
          "type": "data",
          "visible": true
         },
         "fill": "tonexty",
         "fillcolor": "rgba(255, 0, 0, 0.1)",
         "line": {
          "color": "red"
         },
         "mode": "lines",
         "name": "Training Score",
         "type": "scatter",
         "x": [
          280,
          910,
          1540,
          2170,
          2800
         ],
         "y": [
          0.9707142857142858,
          0.9861538461538462,
          0.9800000000000001,
          0.9813824884792627,
          0.9835714285714285
         ]
        },
        {
         "error_y": {
          "array": [
           0.021239162902909482,
           0.004481253468959473,
           0.005221619109284851,
           0.007591617288906501,
           0.0032576440717118228
          ],
          "type": "data",
          "visible": true
         },
         "fill": "tonexty",
         "fillcolor": "rgba(0, 255, 0, 0.1)",
         "line": {
          "color": "green"
         },
         "mode": "lines",
         "name": "Validation Score",
         "type": "scatter",
         "x": [
          280,
          910,
          1540,
          2170,
          2800
         ],
         "y": [
          0.9334285714285715,
          0.968,
          0.9668571428571427,
          0.9719999999999999,
          0.9785714285714286
         ]
        }
       ],
       "layout": {
        "legend": {
         "x": 0.02,
         "y": 0.98
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#C8D4E3"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Learning Curve for Random Forest"
        },
        "xaxis": {
         "showgrid": true,
         "title": {
          "text": "Training Set Size"
         }
        },
        "yaxis": {
         "showgrid": true,
         "title": {
          "text": "Accuracy Score"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "example_plot_voting_learning_curve(X_train_smote,y_train_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Random Forest': {'bootstrap': False, 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 50}, 'Decision Tree': {'criterion': 'entropy', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2}, 'Logistic Regression': {'C': 0.1, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear'}, 'K-Neighbors Classifier': {'algorithm': 'auto', 'n_neighbors': 3, 'p': 2, 'weights': 'distance'}, 'Support Vector Machine': {'C': 10, 'gamma': 'scale', 'kernel': 'rbf', 'probability': True}, 'Naive Bayes': {'var_smoothing': 1e-07}, 'AdaBoost': {'learning_rate': 1, 'n_estimators': 150}, 'Bagging Classifier': {'bootstrap': True, 'max_samples': 1.0, 'n_estimators': 10}}\n"
     ]
    }
   ],
   "source": [
    "with open('best_model_params.json', 'r') as json_file:\n",
    "    best_params = json.load(json_file)\n",
    "    print(best_params)\n",
    "voting_classifier=VotingClassifier(estimators=[\n",
    "            ('lr', LogisticRegression(**best_params.get(\"Logistic Regression\", {}),random_state=42)),\n",
    "            ('rf', RandomForestClassifier(**best_params.get(\"Random Forest\", {}),random_state=42)),\n",
    "            ('gnb', GaussianNB(var_smoothing=1e-8))\n",
    "        ], voting='soft')\n",
    "\n",
    "# Assuming X and y are your dataset and labels\n",
    "def example_plot_voting_learning_curve(X, y):\n",
    "    \n",
    "    # Convert sparse matrices to dense if necessary\n",
    "    if hasattr(X, 'toarray'):\n",
    "        X_train = X.toarray()\n",
    "    plot_learning_curve(voting_classifier, X, y, model_name=\"Voting Classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "error_y": {
          "array": [
           0,
           0.000538349394018279,
           0.0011321815437767937,
           0.0015256170836172014,
           0.004636809247747849
          ],
          "type": "data",
          "visible": true
         },
         "fill": "tonexty",
         "fillcolor": "rgba(255, 0, 0, 0.1)",
         "line": {
          "color": "red"
         },
         "mode": "lines",
         "name": "Training Score",
         "type": "scatter",
         "x": [
          280,
          910,
          1540,
          2170,
          2800
         ],
         "y": [
          1,
          0.9993406593406593,
          0.9984415584415585,
          0.9973271889400921,
          0.9925714285714285
         ]
        },
        {
         "error_y": {
          "array": [
           0.015370260178643173,
           0.007907630001770322,
           0.006477590885002646,
           0.005785273351804759,
           0.00852367650867219
          ],
          "type": "data",
          "visible": true
         },
         "fill": "tonexty",
         "fillcolor": "rgba(0, 255, 0, 0.1)",
         "line": {
          "color": "green"
         },
         "mode": "lines",
         "name": "Validation Score",
         "type": "scatter",
         "x": [
          280,
          910,
          1540,
          2170,
          2800
         ],
         "y": [
          0.9345714285714285,
          0.9748571428571428,
          0.9825714285714285,
          0.9857142857142858,
          0.9828571428571429
         ]
        }
       ],
       "layout": {
        "legend": {
         "x": 0.02,
         "y": 0.98
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#C8D4E3"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Learning Curve for Voting Classifier"
        },
        "xaxis": {
         "showgrid": true,
         "title": {
          "text": "Training Set Size"
         }
        },
        "yaxis": {
         "showgrid": true,
         "title": {
          "text": "Accuracy Score"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "example_plot_voting_learning_curve(X_train_smote,y_train_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg=LogisticRegression(**best_params.get(\"Logistic Regression\", {}),random_state=42)\n",
    "# Assuming X and y are your dataset and labels\n",
    "def example_plot_voting_learning_curve(X, y):\n",
    "    \n",
    "    # Convert sparse matrices to dense if necessary\n",
    "    if hasattr(X, 'toarray'):\n",
    "        X_train = X.toarray()\n",
    "    plot_learning_curve(log_reg, X, y, model_name=\"Logistic Regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "error_y": {
          "array": [
           0.005714285714285739,
           0.0008791208791208761,
           0.0007572664798500717,
           0.000344853215370877,
           0.00041649656391749406
          ],
          "type": "data",
          "visible": true
         },
         "fill": "tonexty",
         "fillcolor": "rgba(255, 0, 0, 0.1)",
         "line": {
          "color": "red"
         },
         "mode": "lines",
         "name": "Training Score",
         "type": "scatter",
         "x": [
          280,
          910,
          1540,
          2170,
          2800
         ],
         "y": [
          0.9935714285714287,
          0.9995604395604396,
          0.9981818181818183,
          0.9980645161290322,
          0.9981428571428571
         ]
        },
        {
         "error_y": {
          "array": [
           0.008329931278350418,
           0.002941608611710568,
           0.002649605284427347,
           0.0027701027756664746,
           0.0033073819722257746
          ],
          "type": "data",
          "visible": true
         },
         "fill": "tonexty",
         "fillcolor": "rgba(0, 255, 0, 0.1)",
         "line": {
          "color": "green"
         },
         "mode": "lines",
         "name": "Validation Score",
         "type": "scatter",
         "x": [
          280,
          910,
          1540,
          2170,
          2800
         ],
         "y": [
          0.9585714285714285,
          0.9834285714285713,
          0.9837142857142858,
          0.9845714285714287,
          0.9868571428571429
         ]
        }
       ],
       "layout": {
        "legend": {
         "x": 0.02,
         "y": 0.98
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#C8D4E3"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Learning Curve for Logistic Regression"
        },
        "xaxis": {
         "showgrid": true,
         "title": {
          "text": "Training Set Size"
         }
        },
        "yaxis": {
         "showgrid": true,
         "title": {
          "text": "Accuracy Score"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "example_plot_voting_learning_curve(X_train_smote,y_train_smote)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All three models have LowBias and LowVariance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
